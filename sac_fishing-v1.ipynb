{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sac_fishing-v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIziE1HhKlPbaw2TE+DRkW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NC25/gym_fishing/blob/master/sac_fishing-v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTpx7I-ne2EV",
        "colab_type": "text"
      },
      "source": [
        "# Soft Actor Critic\n",
        "\n",
        "The Soft Actor Critic  is popular agent used for the training of large and continous domains. \n",
        "\n",
        "*   Off-policy -  trains on many different actions that are not included in the policy, which encourages entropy.\n",
        "*   Maxes expected reward and entropy\n",
        "\n",
        "*   Agent gets a bonus reward at each time-step proportional to the \n",
        "instantaneous entropy\n",
        "*   Optimizes policy while approximating Q functions)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UroV7D__iskF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install -y xvfb ffmpeg\n",
        "!pip install 'gym==0.10.11'\n",
        "!pip install 'imageio==2.4.0'\n",
        "!pip install matplotlib\n",
        "!pip install PILLOW\n",
        "!pip install tf-agents\n",
        "!pip install 'pybullet==2.4.2'\n",
        "!pip install 'pyglet==1.3.2'\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install --upgrade setuptools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7YXMlJAuS4i",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameter Tuning (optional)\n",
        "\n",
        "Dependencies to set up Baselines Zoo for Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY9TU8VkkI3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!apt-get install swig cmake libopenmpi-dev zlib1g-dev ffmpeg\n",
        "#!pip install stable-baselines box2d box2d-kengz pyyaml pybullet optuna pytablewriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M90LcXocgDD",
        "colab_type": "text"
      },
      "source": [
        "# Dependencies\n",
        "Run the following dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3BFySVaerOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install stable-baselines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfS5y8NCFhNk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "6b20e0d5-24c4-475b-a3d0-4ba836550221"
      },
      "source": [
        "#!pip install pyglet==1.5.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyglet==1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/ca/20aee170afe6011e295e34b27ad7d7ccd795faba581dd3c6f7cec237f561/pyglet-1.5.0-py2.py3-none-any.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet==1.5.0) (0.16.0)\n",
            "Installing collected packages: pyglet\n",
            "  Found existing installation: pyglet 1.5.7\n",
            "    Uninstalling pyglet-1.5.7:\n",
            "      Successfully uninstalled pyglet-1.5.7\n",
            "Successfully installed pyglet-1.5.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyglet"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEwGJPzVjbQO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bb756ca6-d1f3-47c7-a1a0-e9a50d91f386"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!apt-get install ffmpeg freeglut3-dev xvfb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "freeglut3-dev is already the newest version (2.8.1-3).\n",
            "ffmpeg is already the newest version (7:3.4.6-0ubuntu0.18.04.1).\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.4).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdNRcthla9xK",
        "colab_type": "text"
      },
      "source": [
        "Downgrade tensor flow to version 1.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oJTqt03m2Z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorflow==1.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI-vd_1cbCPS",
        "colab_type": "text"
      },
      "source": [
        "# Clone Repository\n",
        "\n",
        "Cloning must follow this order!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MwSVma6WhN4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1300fe4-5fa5-4338-e9e2-3e9e22f91e6d"
      },
      "source": [
        " !git clone https://github.com/boettiger-lab/gym_fishing.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'gym_fishing' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kU-hBacKWtoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python gym_fishing/setup.py sdist bdist_wheel "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQGoeEE-WwwQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "deb6192f-058c-4fac-abfc-2d7fa7ac23a8"
      },
      "source": [
        "!pip install -e ./gym_fishing/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/gym_fishing\n",
            "Installing collected packages: gym-fishing\n",
            "  Found existing installation: gym-fishing 0.0.2\n",
            "    Can't uninstall 'gym-fishing'. No files were found to uninstall.\n",
            "  Running setup.py develop for gym-fishing\n",
            "Successfully installed gym-fishing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr5xm9GcWjKg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "161f9c55-1f61-442e-d417-f3dda9650049"
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "build  dist  gym_fishing  gym_fishing.egg-info\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUfLjW8ZWniY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd gym_fishing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCBUp7pAW1Hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym_fishing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyza6m1fH7XQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_Z5tjdrjurO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "from stable_baselines.sac.policies import MlpPolicy\n",
        "from stable_baselines import SAC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUxue6OEdAEd",
        "colab_type": "text"
      },
      "source": [
        "# Load Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSmRa108_D-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make('fishing-v1')\n",
        "\n",
        "model = SAC(MlpPolicy, env, verbose=1) #verbose = 1 includes progress bar and \n",
        "#loading line\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJOPTPg2dVKG",
        "colab_type": "text"
      },
      "source": [
        "# Helper Function\n",
        "\n",
        "This helper function will be used to evaluate our un-trained agent. It will instantiate the environment and return observations for every time step.\n",
        "\n",
        "Then it will return a reward based on the state and action. Finally it will append the reward to our utility (the collection of our rewards)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X7Gq6raCDqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8fe678a3-a5b7-4e6a-f72c-92c4462e8964"
      },
      "source": [
        "def evaluate(model, num_episodes=100):\n",
        "    \n",
        "    # This function will only work for a single Environment\n",
        "    env = model.get_env()\n",
        "    all_episode_rewards = []\n",
        "    for i in range(num_episodes):\n",
        "        episode_rewards = []\n",
        "        done = False\n",
        "        obs = env.reset()\n",
        "        while not done:\n",
        "            action, _states = model.predict(obs)\n",
        "            obs, reward, done, info = env.step(action)\n",
        "            episode_rewards.append(reward)\n",
        "\n",
        "        all_episode_rewards.append(sum(episode_rewards))\n",
        "\n",
        "    mean_episode_reward = np.mean(all_episode_rewards)\n",
        "    print(\"Mean reward:\", mean_episode_reward, \"Num episodes:\", num_episodes)\n",
        "\n",
        "    return mean_episode_reward #mean reward for the last episode\n",
        "\n",
        "mean_reward_before_train = evaluate(model, num_episodes=250)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean reward: 0.75 Num episodes: 250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVBiBg-Ptwgf",
        "colab_type": "text"
      },
      "source": [
        "We can see the results when we evaluate our untrained agent.\n",
        "\n",
        "So let's start training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp7iOtWinHw4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0feb5222-9fd4-405a-b737-f0375eb7b365"
      },
      "source": [
        "\n",
        "model = SAC(MlpPolicy, env, verbose=1)\n",
        "model.learn(total_timesteps=50000, log_interval=10)\n",
        "model.save(\"fishing-v1\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "| policy_loss             | -0.5982082    |\n",
            "| qf1_loss                | 5.4603765e-07 |\n",
            "| qf2_loss                | 2.4431975e-07 |\n",
            "| time_elapsed            | 118           |\n",
            "| total timesteps         | 23143         |\n",
            "| value_loss              | 8.019773e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0071541476  |\n",
            "| ent_coef_loss           | 1.2977657     |\n",
            "| entropy                 | 0.9696589     |\n",
            "| episodes                | 9060          |\n",
            "| fps                     | 194           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 23115         |\n",
            "| policy_loss             | -0.64237183   |\n",
            "| qf1_loss                | 3.9034663e-07 |\n",
            "| qf2_loss                | 3.3640067e-06 |\n",
            "| time_elapsed            | 119           |\n",
            "| total timesteps         | 23214         |\n",
            "| value_loss              | 9.7257136e-05 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0071605877  |\n",
            "| ent_coef_loss           | -0.50512826   |\n",
            "| entropy                 | 1.0785849     |\n",
            "| episodes                | 9070          |\n",
            "| fps                     | 194           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 23186         |\n",
            "| policy_loss             | -0.6182482    |\n",
            "| qf1_loss                | 3.3460194e-06 |\n",
            "| qf2_loss                | 2.4076546e-06 |\n",
            "| time_elapsed            | 119           |\n",
            "| total timesteps         | 23285         |\n",
            "| value_loss              | 0.000103584   |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.0071583176   |\n",
            "| ent_coef_loss           | -0.40761545    |\n",
            "| entropy                 | 1.1200056      |\n",
            "| episodes                | 9080           |\n",
            "| fps                     | 194            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 23263          |\n",
            "| policy_loss             | -0.56669164    |\n",
            "| qf1_loss                | 1.4285519e-07  |\n",
            "| qf2_loss                | 1.9393525e-07  |\n",
            "| time_elapsed            | 119            |\n",
            "| total timesteps         | 23362          |\n",
            "| value_loss              | 0.000106997584 |\n",
            "--------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.0071383226   |\n",
            "| ent_coef_loss           | 0.14391267     |\n",
            "| entropy                 | 1.0924153      |\n",
            "| episodes                | 9090           |\n",
            "| fps                     | 195            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 23344          |\n",
            "| policy_loss             | -0.6089495     |\n",
            "| qf1_loss                | 1.2651337e-06  |\n",
            "| qf2_loss                | 2.456307e-07   |\n",
            "| time_elapsed            | 120            |\n",
            "| total timesteps         | 23443          |\n",
            "| value_loss              | 0.000100875695 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0070912745  |\n",
            "| ent_coef_loss           | 0.17732725    |\n",
            "| entropy                 | 0.98579454    |\n",
            "| episodes                | 9100          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 23419         |\n",
            "| policy_loss             | -0.65227383   |\n",
            "| qf1_loss                | 2.404226e-07  |\n",
            "| qf2_loss                | 3.8283724e-07 |\n",
            "| time_elapsed            | 120           |\n",
            "| total timesteps         | 23518         |\n",
            "| value_loss              | 9.991387e-05  |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.007100183    |\n",
            "| ent_coef_loss           | -0.773762      |\n",
            "| entropy                 | 1.0396448      |\n",
            "| episodes                | 9110           |\n",
            "| fps                     | 195            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 23497          |\n",
            "| policy_loss             | -0.6234515     |\n",
            "| qf1_loss                | 1.1045202e-06  |\n",
            "| qf2_loss                | 8.616333e-07   |\n",
            "| time_elapsed            | 120            |\n",
            "| total timesteps         | 23596          |\n",
            "| value_loss              | 0.000110216555 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007140934   |\n",
            "| ent_coef_loss           | 0.5170593     |\n",
            "| entropy                 | 0.9855826     |\n",
            "| episodes                | 9120          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 23584         |\n",
            "| policy_loss             | -0.64358723   |\n",
            "| qf1_loss                | 2.131344e-07  |\n",
            "| qf2_loss                | 3.8786524e-07 |\n",
            "| time_elapsed            | 121           |\n",
            "| total timesteps         | 23683         |\n",
            "| value_loss              | 6.770791e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007122893   |\n",
            "| ent_coef_loss           | 0.6254666     |\n",
            "| entropy                 | 1.0132991     |\n",
            "| episodes                | 9130          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 23662         |\n",
            "| policy_loss             | -0.58191013   |\n",
            "| qf1_loss                | 2.3560365e-07 |\n",
            "| qf2_loss                | 2.6507837e-07 |\n",
            "| time_elapsed            | 121           |\n",
            "| total timesteps         | 23761         |\n",
            "| value_loss              | 7.991758e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007138748   |\n",
            "| ent_coef_loss           | -0.950346     |\n",
            "| entropy                 | 1.0285311     |\n",
            "| episodes                | 9140          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 23735         |\n",
            "| policy_loss             | -0.6137537    |\n",
            "| qf1_loss                | 1.7459992e-07 |\n",
            "| qf2_loss                | 1.2816014e-07 |\n",
            "| time_elapsed            | 122           |\n",
            "| total timesteps         | 23834         |\n",
            "| value_loss              | 0.00012560631 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007148129   |\n",
            "| ent_coef_loss           | -0.41479665   |\n",
            "| entropy                 | 1.0593591     |\n",
            "| episodes                | 9150          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 23810         |\n",
            "| policy_loss             | -0.6094017    |\n",
            "| qf1_loss                | 3.5729732e-07 |\n",
            "| qf2_loss                | 1.3659383e-06 |\n",
            "| time_elapsed            | 122           |\n",
            "| total timesteps         | 23909         |\n",
            "| value_loss              | 0.00013001563 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00718309    |\n",
            "| ent_coef_loss           | 1.219098      |\n",
            "| entropy                 | 0.96662885    |\n",
            "| episodes                | 9160          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 23895         |\n",
            "| policy_loss             | -0.6348876    |\n",
            "| qf1_loss                | 6.682618e-07  |\n",
            "| qf2_loss                | 4.8003955e-07 |\n",
            "| time_elapsed            | 122           |\n",
            "| total timesteps         | 23994         |\n",
            "| value_loss              | 5.0525327e-05 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0072258464  |\n",
            "| ent_coef_loss           | 0.19221866    |\n",
            "| entropy                 | 1.0019786     |\n",
            "| episodes                | 9170          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 23984         |\n",
            "| policy_loss             | -0.62995464   |\n",
            "| qf1_loss                | 2.424342e-07  |\n",
            "| qf2_loss                | 4.243985e-07  |\n",
            "| time_elapsed            | 123           |\n",
            "| total timesteps         | 24083         |\n",
            "| value_loss              | 0.00013002769 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007211675   |\n",
            "| ent_coef_loss           | -0.0082734525 |\n",
            "| entropy                 | 0.9945787     |\n",
            "| episodes                | 9180          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 24060         |\n",
            "| policy_loss             | -0.6106445    |\n",
            "| qf1_loss                | 5.1963417e-07 |\n",
            "| qf2_loss                | 4.538941e-07  |\n",
            "| time_elapsed            | 123           |\n",
            "| total timesteps         | 24159         |\n",
            "| value_loss              | 9.567661e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007243896   |\n",
            "| ent_coef_loss           | 1.0422976     |\n",
            "| entropy                 | 0.9822491     |\n",
            "| episodes                | 9190          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 24124         |\n",
            "| policy_loss             | -0.6405393    |\n",
            "| qf1_loss                | 1.7708798e-07 |\n",
            "| qf2_loss                | 4.1074776e-07 |\n",
            "| time_elapsed            | 123           |\n",
            "| total timesteps         | 24223         |\n",
            "| value_loss              | 8.87922e-05   |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0072652777  |\n",
            "| ent_coef_loss           | 0.9956869     |\n",
            "| entropy                 | 1.0007782     |\n",
            "| episodes                | 9200          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 24199         |\n",
            "| policy_loss             | -0.627782     |\n",
            "| qf1_loss                | 8.6955936e-07 |\n",
            "| qf2_loss                | 3.9304535e-07 |\n",
            "| time_elapsed            | 124           |\n",
            "| total timesteps         | 24298         |\n",
            "| value_loss              | 9.859323e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007262756   |\n",
            "| ent_coef_loss           | 1.0626221     |\n",
            "| entropy                 | 1.0191482     |\n",
            "| episodes                | 9210          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 24270         |\n",
            "| policy_loss             | -0.60267365   |\n",
            "| qf1_loss                | 2.7917798e-07 |\n",
            "| qf2_loss                | 3.6945883e-07 |\n",
            "| time_elapsed            | 124           |\n",
            "| total timesteps         | 24369         |\n",
            "| value_loss              | 7.381139e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007259612   |\n",
            "| ent_coef_loss           | 1.5424485     |\n",
            "| entropy                 | 1.0115187     |\n",
            "| episodes                | 9220          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 24351         |\n",
            "| policy_loss             | -0.621356     |\n",
            "| qf1_loss                | 2.280029e-07  |\n",
            "| qf2_loss                | 4.0351046e-07 |\n",
            "| time_elapsed            | 125           |\n",
            "| total timesteps         | 24450         |\n",
            "| value_loss              | 8.0882295e-05 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.0072753034   |\n",
            "| ent_coef_loss           | 0.05824603     |\n",
            "| entropy                 | 0.9899448      |\n",
            "| episodes                | 9230           |\n",
            "| fps                     | 195            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 24435          |\n",
            "| policy_loss             | -0.6286658     |\n",
            "| qf1_loss                | 5.0270637e-07  |\n",
            "| qf2_loss                | 3.8644419e-07  |\n",
            "| time_elapsed            | 125            |\n",
            "| total timesteps         | 24534          |\n",
            "| value_loss              | 0.000119466546 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007262728   |\n",
            "| ent_coef_loss           | 0.12863776    |\n",
            "| entropy                 | 1.0336237     |\n",
            "| episodes                | 9240          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 24483         |\n",
            "| policy_loss             | -0.6301842    |\n",
            "| qf1_loss                | 1.5280066e-06 |\n",
            "| qf2_loss                | 4.0717242e-07 |\n",
            "| time_elapsed            | 125           |\n",
            "| total timesteps         | 24582         |\n",
            "| value_loss              | 0.0001121168  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007275189   |\n",
            "| ent_coef_loss           | 0.51189387    |\n",
            "| entropy                 | 0.9336269     |\n",
            "| episodes                | 9250          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 24561         |\n",
            "| policy_loss             | -0.66389513   |\n",
            "| qf1_loss                | 5.6296614e-07 |\n",
            "| qf2_loss                | 3.300313e-07  |\n",
            "| time_elapsed            | 126           |\n",
            "| total timesteps         | 24660         |\n",
            "| value_loss              | 9.659318e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007281155   |\n",
            "| ent_coef_loss           | -1.0438396    |\n",
            "| entropy                 | 1.0318987     |\n",
            "| episodes                | 9260          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 24656         |\n",
            "| policy_loss             | -0.5925971    |\n",
            "| qf1_loss                | 3.04737e-07   |\n",
            "| qf2_loss                | 4.5608317e-07 |\n",
            "| time_elapsed            | 126           |\n",
            "| total timesteps         | 24755         |\n",
            "| value_loss              | 9.979322e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007280089   |\n",
            "| ent_coef_loss           | 1.1758858     |\n",
            "| entropy                 | 1.0144497     |\n",
            "| episodes                | 9270          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 24731         |\n",
            "| policy_loss             | -0.61364853   |\n",
            "| qf1_loss                | 2.91013e-07   |\n",
            "| qf2_loss                | 5.9294973e-07 |\n",
            "| time_elapsed            | 126           |\n",
            "| total timesteps         | 24830         |\n",
            "| value_loss              | 8.007088e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0072915535  |\n",
            "| ent_coef_loss           | 1.2709856     |\n",
            "| entropy                 | 0.937178      |\n",
            "| episodes                | 9280          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 24810         |\n",
            "| policy_loss             | -0.66510963   |\n",
            "| qf1_loss                | 1.5130229e-07 |\n",
            "| qf2_loss                | 5.9072073e-07 |\n",
            "| time_elapsed            | 127           |\n",
            "| total timesteps         | 24909         |\n",
            "| value_loss              | 0.00011149443 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007326528   |\n",
            "| ent_coef_loss           | 1.7442176     |\n",
            "| entropy                 | 0.9675453     |\n",
            "| episodes                | 9290          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 24905         |\n",
            "| policy_loss             | -0.62122      |\n",
            "| qf1_loss                | 2.5854806e-07 |\n",
            "| qf2_loss                | 4.5057428e-07 |\n",
            "| time_elapsed            | 127           |\n",
            "| total timesteps         | 25004         |\n",
            "| value_loss              | 8.087041e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007342833   |\n",
            "| ent_coef_loss           | 0.59564364    |\n",
            "| entropy                 | 0.9033659     |\n",
            "| episodes                | 9300          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 24973         |\n",
            "| policy_loss             | -0.68370664   |\n",
            "| qf1_loss                | 2.267727e-07  |\n",
            "| qf2_loss                | 1.7779968e-07 |\n",
            "| time_elapsed            | 128           |\n",
            "| total timesteps         | 25072         |\n",
            "| value_loss              | 0.00013633608 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0073516686  |\n",
            "| ent_coef_loss           | -1.1909482    |\n",
            "| entropy                 | 1.009661      |\n",
            "| episodes                | 9310          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 25048         |\n",
            "| policy_loss             | -0.5930735    |\n",
            "| qf1_loss                | 3.087029e-07  |\n",
            "| qf2_loss                | 5.421896e-07  |\n",
            "| time_elapsed            | 128           |\n",
            "| total timesteps         | 25147         |\n",
            "| value_loss              | 0.00010228372 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007375436   |\n",
            "| ent_coef_loss           | -0.4414199    |\n",
            "| entropy                 | 0.9656945     |\n",
            "| episodes                | 9320          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 25128         |\n",
            "| policy_loss             | -0.6256638    |\n",
            "| qf1_loss                | 5.309811e-07  |\n",
            "| qf2_loss                | 2.0680226e-07 |\n",
            "| time_elapsed            | 128           |\n",
            "| total timesteps         | 25227         |\n",
            "| value_loss              | 0.0001220915  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0073799705  |\n",
            "| ent_coef_loss           | -1.1423154    |\n",
            "| entropy                 | 1.0003924     |\n",
            "| episodes                | 9330          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 25202         |\n",
            "| policy_loss             | -0.6052158    |\n",
            "| qf1_loss                | 2.9381457e-07 |\n",
            "| qf2_loss                | 2.9176533e-07 |\n",
            "| time_elapsed            | 129           |\n",
            "| total timesteps         | 25301         |\n",
            "| value_loss              | 0.0001452759  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0073998272  |\n",
            "| ent_coef_loss           | 0.23506209    |\n",
            "| entropy                 | 0.9879053     |\n",
            "| episodes                | 9340          |\n",
            "| fps                     | 195           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 25302         |\n",
            "| policy_loss             | -0.61872      |\n",
            "| qf1_loss                | 2.5078344e-07 |\n",
            "| qf2_loss                | 5.51311e-07   |\n",
            "| time_elapsed            | 129           |\n",
            "| total timesteps         | 25401         |\n",
            "| value_loss              | 8.330649e-05  |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.0074065556   |\n",
            "| ent_coef_loss           | -0.5288405     |\n",
            "| entropy                 | 1.0650291      |\n",
            "| episodes                | 9350           |\n",
            "| fps                     | 196            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 25371          |\n",
            "| policy_loss             | -0.57005906    |\n",
            "| qf1_loss                | 7.934634e-07   |\n",
            "| qf2_loss                | 3.364902e-07   |\n",
            "| time_elapsed            | 129            |\n",
            "| total timesteps         | 25470          |\n",
            "| value_loss              | 0.000109629196 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00743207    |\n",
            "| ent_coef_loss           | 0.21649742    |\n",
            "| entropy                 | 0.9686613     |\n",
            "| episodes                | 9360          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 25452         |\n",
            "| policy_loss             | -0.6035865    |\n",
            "| qf1_loss                | 2.439731e-07  |\n",
            "| qf2_loss                | 3.7260136e-07 |\n",
            "| time_elapsed            | 130           |\n",
            "| total timesteps         | 25551         |\n",
            "| value_loss              | 0.00014837121 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0074541387  |\n",
            "| ent_coef_loss           | 0.5818485     |\n",
            "| entropy                 | 0.98503315    |\n",
            "| episodes                | 9370          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 25531         |\n",
            "| policy_loss             | -0.64166003   |\n",
            "| qf1_loss                | 3.2665514e-07 |\n",
            "| qf2_loss                | 6.538653e-07  |\n",
            "| time_elapsed            | 130           |\n",
            "| total timesteps         | 25630         |\n",
            "| value_loss              | 0.00013982847 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.0074352073   |\n",
            "| ent_coef_loss           | 0.15624318     |\n",
            "| entropy                 | 0.9449178      |\n",
            "| episodes                | 9380           |\n",
            "| fps                     | 196            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 25608          |\n",
            "| policy_loss             | -0.6039816     |\n",
            "| qf1_loss                | 4.506382e-07   |\n",
            "| qf2_loss                | 7.710328e-07   |\n",
            "| time_elapsed            | 131            |\n",
            "| total timesteps         | 25707          |\n",
            "| value_loss              | 0.000110325724 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0074500274  |\n",
            "| ent_coef_loss           | -0.22950321   |\n",
            "| entropy                 | 1.0526365     |\n",
            "| episodes                | 9390          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 25691         |\n",
            "| policy_loss             | -0.58835363   |\n",
            "| qf1_loss                | 8.9456597e-07 |\n",
            "| qf2_loss                | 7.226332e-07  |\n",
            "| time_elapsed            | 131           |\n",
            "| total timesteps         | 25790         |\n",
            "| value_loss              | 0.00014451676 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007414174   |\n",
            "| ent_coef_loss           | -0.5147402    |\n",
            "| entropy                 | 1.025991      |\n",
            "| episodes                | 9400          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 25752         |\n",
            "| policy_loss             | -0.63469666   |\n",
            "| qf1_loss                | 1.0033148e-06 |\n",
            "| qf2_loss                | 1.3795605e-07 |\n",
            "| time_elapsed            | 131           |\n",
            "| total timesteps         | 25851         |\n",
            "| value_loss              | 8.8864035e-05 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0073959962  |\n",
            "| ent_coef_loss           | -0.5747818    |\n",
            "| entropy                 | 0.91535455    |\n",
            "| episodes                | 9410          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 25835         |\n",
            "| policy_loss             | -0.65475225   |\n",
            "| qf1_loss                | 1.088755e-06  |\n",
            "| qf2_loss                | 3.5957012e-07 |\n",
            "| time_elapsed            | 132           |\n",
            "| total timesteps         | 25934         |\n",
            "| value_loss              | 8.67589e-05   |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.0074097593   |\n",
            "| ent_coef_loss           | 0.5559511      |\n",
            "| entropy                 | 1.0276669      |\n",
            "| episodes                | 9420           |\n",
            "| fps                     | 196            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 25906          |\n",
            "| policy_loss             | -0.62954426    |\n",
            "| qf1_loss                | 3.9189223e-07  |\n",
            "| qf2_loss                | 1.4070231e-06  |\n",
            "| time_elapsed            | 132            |\n",
            "| total timesteps         | 26005          |\n",
            "| value_loss              | 0.000114848466 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0073983134  |\n",
            "| ent_coef_loss           | 0.9923696     |\n",
            "| entropy                 | 0.9616686     |\n",
            "| episodes                | 9430          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 25997         |\n",
            "| policy_loss             | -0.6205218    |\n",
            "| qf1_loss                | 4.834261e-07  |\n",
            "| qf2_loss                | 1.6579884e-07 |\n",
            "| time_elapsed            | 132           |\n",
            "| total timesteps         | 26096         |\n",
            "| value_loss              | 8.446643e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0074617383  |\n",
            "| ent_coef_loss           | -0.7594296    |\n",
            "| entropy                 | 1.0185225     |\n",
            "| episodes                | 9440          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 26086         |\n",
            "| policy_loss             | -0.628397     |\n",
            "| qf1_loss                | 2.4194526e-07 |\n",
            "| qf2_loss                | 1.0706468e-07 |\n",
            "| time_elapsed            | 133           |\n",
            "| total timesteps         | 26185         |\n",
            "| value_loss              | 0.00015163071 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.007455472    |\n",
            "| ent_coef_loss           | 0.7156374      |\n",
            "| entropy                 | 0.92574537     |\n",
            "| episodes                | 9450           |\n",
            "| fps                     | 196            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 26154          |\n",
            "| policy_loss             | -0.6374825     |\n",
            "| qf1_loss                | 4.590743e-07   |\n",
            "| qf2_loss                | 6.412803e-07   |\n",
            "| time_elapsed            | 133            |\n",
            "| total timesteps         | 26253          |\n",
            "| value_loss              | 0.000104899635 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0075240205  |\n",
            "| ent_coef_loss           | -0.20903611   |\n",
            "| entropy                 | 0.91984403    |\n",
            "| episodes                | 9460          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 26246         |\n",
            "| policy_loss             | -0.6634568    |\n",
            "| qf1_loss                | 1.1102131e-06 |\n",
            "| qf2_loss                | 1.5011154e-06 |\n",
            "| time_elapsed            | 134           |\n",
            "| total timesteps         | 26345         |\n",
            "| value_loss              | 0.00015718308 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007554697   |\n",
            "| ent_coef_loss           | 0.92462814    |\n",
            "| entropy                 | 0.92628384    |\n",
            "| episodes                | 9470          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 26349         |\n",
            "| policy_loss             | -0.6455444    |\n",
            "| qf1_loss                | 3.377199e-07  |\n",
            "| qf2_loss                | 1.3037336e-06 |\n",
            "| time_elapsed            | 134           |\n",
            "| total timesteps         | 26448         |\n",
            "| value_loss              | 8.0041485e-05 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0075841895  |\n",
            "| ent_coef_loss           | 0.47687244    |\n",
            "| entropy                 | 0.97548234    |\n",
            "| episodes                | 9480          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 26439         |\n",
            "| policy_loss             | -0.62010807   |\n",
            "| qf1_loss                | 3.9954023e-07 |\n",
            "| qf2_loss                | 5.869536e-07  |\n",
            "| time_elapsed            | 135           |\n",
            "| total timesteps         | 26538         |\n",
            "| value_loss              | 0.00010352283 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007617599   |\n",
            "| ent_coef_loss           | 0.895926      |\n",
            "| entropy                 | 0.87157947    |\n",
            "| episodes                | 9490          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 26518         |\n",
            "| policy_loss             | -0.672274     |\n",
            "| qf1_loss                | 3.7685302e-06 |\n",
            "| qf2_loss                | 2.0589243e-07 |\n",
            "| time_elapsed            | 135           |\n",
            "| total timesteps         | 26617         |\n",
            "| value_loss              | 0.00013025483 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0076245945  |\n",
            "| ent_coef_loss           | 0.63104117    |\n",
            "| entropy                 | 0.92001766    |\n",
            "| episodes                | 9500          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 26591         |\n",
            "| policy_loss             | -0.6297541    |\n",
            "| qf1_loss                | 4.8763627e-07 |\n",
            "| qf2_loss                | 9.773096e-07  |\n",
            "| time_elapsed            | 135           |\n",
            "| total timesteps         | 26690         |\n",
            "| value_loss              | 7.594926e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007646549   |\n",
            "| ent_coef_loss           | 0.28667617    |\n",
            "| entropy                 | 0.91434467    |\n",
            "| episodes                | 9510          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 26647         |\n",
            "| policy_loss             | -0.6370725    |\n",
            "| qf1_loss                | 9.964539e-07  |\n",
            "| qf2_loss                | 2.8044713e-07 |\n",
            "| time_elapsed            | 136           |\n",
            "| total timesteps         | 26746         |\n",
            "| value_loss              | 8.006948e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0076770955  |\n",
            "| ent_coef_loss           | -0.21660206   |\n",
            "| entropy                 | 0.9562495     |\n",
            "| episodes                | 9520          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 26725         |\n",
            "| policy_loss             | -0.63299054   |\n",
            "| qf1_loss                | 4.7286386e-07 |\n",
            "| qf2_loss                | 5.39688e-07   |\n",
            "| time_elapsed            | 136           |\n",
            "| total timesteps         | 26824         |\n",
            "| value_loss              | 0.00010246206 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0076971385  |\n",
            "| ent_coef_loss           | 0.03571275    |\n",
            "| entropy                 | 0.9356941     |\n",
            "| episodes                | 9530          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 26773         |\n",
            "| policy_loss             | -0.6427944    |\n",
            "| qf1_loss                | 9.2152425e-07 |\n",
            "| qf2_loss                | 4.468563e-07  |\n",
            "| time_elapsed            | 136           |\n",
            "| total timesteps         | 26872         |\n",
            "| value_loss              | 0.00011837593 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.0076795705   |\n",
            "| ent_coef_loss           | -0.5043908     |\n",
            "| entropy                 | 1.034797       |\n",
            "| episodes                | 9540           |\n",
            "| fps                     | 196            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 26861          |\n",
            "| policy_loss             | -0.6104319     |\n",
            "| qf1_loss                | 6.6735436e-07  |\n",
            "| qf2_loss                | 7.7954684e-07  |\n",
            "| time_elapsed            | 137            |\n",
            "| total timesteps         | 26960          |\n",
            "| value_loss              | 0.000101072816 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0076678833  |\n",
            "| ent_coef_loss           | 0.7276331     |\n",
            "| entropy                 | 0.97990215    |\n",
            "| episodes                | 9550          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 26913         |\n",
            "| policy_loss             | -0.61890066   |\n",
            "| qf1_loss                | 1.4962825e-06 |\n",
            "| qf2_loss                | 6.376342e-07  |\n",
            "| time_elapsed            | 137           |\n",
            "| total timesteps         | 27012         |\n",
            "| value_loss              | 0.00012317288 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007741404   |\n",
            "| ent_coef_loss           | 0.8883469     |\n",
            "| entropy                 | 0.9568245     |\n",
            "| episodes                | 9560          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 26992         |\n",
            "| policy_loss             | -0.6053729    |\n",
            "| qf1_loss                | 6.0862965e-07 |\n",
            "| qf2_loss                | 2.3758936e-07 |\n",
            "| time_elapsed            | 137           |\n",
            "| total timesteps         | 27091         |\n",
            "| value_loss              | 7.582124e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0077393483  |\n",
            "| ent_coef_loss           | -0.8681383    |\n",
            "| entropy                 | 1.0017633     |\n",
            "| episodes                | 9570          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 27078         |\n",
            "| policy_loss             | -0.5938607    |\n",
            "| qf1_loss                | 8.6571845e-07 |\n",
            "| qf2_loss                | 1.0014107e-06 |\n",
            "| time_elapsed            | 138           |\n",
            "| total timesteps         | 27177         |\n",
            "| value_loss              | 0.00010086646 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.0077285394   |\n",
            "| ent_coef_loss           | -0.44337142    |\n",
            "| entropy                 | 0.94519347     |\n",
            "| episodes                | 9580           |\n",
            "| fps                     | 196            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 27153          |\n",
            "| policy_loss             | -0.60692835    |\n",
            "| qf1_loss                | 5.8057157e-07  |\n",
            "| qf2_loss                | 2.7290818e-07  |\n",
            "| time_elapsed            | 138            |\n",
            "| total timesteps         | 27252          |\n",
            "| value_loss              | 0.000104752726 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007742707   |\n",
            "| ent_coef_loss           | -0.17346895   |\n",
            "| entropy                 | 0.9397247     |\n",
            "| episodes                | 9590          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 27245         |\n",
            "| policy_loss             | -0.6376219    |\n",
            "| qf1_loss                | 6.493728e-07  |\n",
            "| qf2_loss                | 7.8077005e-07 |\n",
            "| time_elapsed            | 138           |\n",
            "| total timesteps         | 27344         |\n",
            "| value_loss              | 9.486422e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0077634766  |\n",
            "| ent_coef_loss           | 1.3004923     |\n",
            "| entropy                 | 0.9418897     |\n",
            "| episodes                | 9600          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 27332         |\n",
            "| policy_loss             | -0.64201057   |\n",
            "| qf1_loss                | 4.388419e-06  |\n",
            "| qf2_loss                | 2.7298415e-07 |\n",
            "| time_elapsed            | 139           |\n",
            "| total timesteps         | 27431         |\n",
            "| value_loss              | 9.525751e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0077680647  |\n",
            "| ent_coef_loss           | -0.7064688    |\n",
            "| entropy                 | 1.032518      |\n",
            "| episodes                | 9610          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 27405         |\n",
            "| policy_loss             | -0.55125153   |\n",
            "| qf1_loss                | 3.5707874e-06 |\n",
            "| qf2_loss                | 3.5728442e-07 |\n",
            "| time_elapsed            | 139           |\n",
            "| total timesteps         | 27504         |\n",
            "| value_loss              | 8.791979e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0077645173  |\n",
            "| ent_coef_loss           | -1.3914026    |\n",
            "| entropy                 | 1.0400892     |\n",
            "| episodes                | 9620          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 27489         |\n",
            "| policy_loss             | -0.58173466   |\n",
            "| qf1_loss                | 6.787586e-07  |\n",
            "| qf2_loss                | 3.5162114e-07 |\n",
            "| time_elapsed            | 140           |\n",
            "| total timesteps         | 27588         |\n",
            "| value_loss              | 0.00011729193 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007814374   |\n",
            "| ent_coef_loss           | 1.478255      |\n",
            "| entropy                 | 0.88418794    |\n",
            "| episodes                | 9630          |\n",
            "| fps                     | 196           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 27577         |\n",
            "| policy_loss             | -0.6334185    |\n",
            "| qf1_loss                | 6.1110103e-07 |\n",
            "| qf2_loss                | 6.188363e-07  |\n",
            "| time_elapsed            | 140           |\n",
            "| total timesteps         | 27676         |\n",
            "| value_loss              | 7.781197e-05  |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.007866445    |\n",
            "| ent_coef_loss           | -0.20422286    |\n",
            "| entropy                 | 0.93308353     |\n",
            "| episodes                | 9640           |\n",
            "| fps                     | 196            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 27653          |\n",
            "| policy_loss             | -0.6344376     |\n",
            "| qf1_loss                | 6.1453966e-07  |\n",
            "| qf2_loss                | 9.511849e-07   |\n",
            "| time_elapsed            | 140            |\n",
            "| total timesteps         | 27752          |\n",
            "| value_loss              | 0.000109733795 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007859336   |\n",
            "| ent_coef_loss           | 0.24313164    |\n",
            "| entropy                 | 0.9265679     |\n",
            "| episodes                | 9650          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 27733         |\n",
            "| policy_loss             | -0.64692026   |\n",
            "| qf1_loss                | 2.3393663e-06 |\n",
            "| qf2_loss                | 4.985835e-07  |\n",
            "| time_elapsed            | 141           |\n",
            "| total timesteps         | 27832         |\n",
            "| value_loss              | 0.00012796432 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.007838636    |\n",
            "| ent_coef_loss           | 1.0097386      |\n",
            "| entropy                 | 0.883669       |\n",
            "| episodes                | 9660           |\n",
            "| fps                     | 197            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 27837          |\n",
            "| policy_loss             | -0.6676299     |\n",
            "| qf1_loss                | 5.870561e-07   |\n",
            "| qf2_loss                | 9.05889e-07    |\n",
            "| time_elapsed            | 141            |\n",
            "| total timesteps         | 27936          |\n",
            "| value_loss              | 0.000119014454 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0078483485  |\n",
            "| ent_coef_loss           | -0.08981389   |\n",
            "| entropy                 | 0.92452335    |\n",
            "| episodes                | 9670          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 27904         |\n",
            "| policy_loss             | -0.6364489    |\n",
            "| qf1_loss                | 6.2752457e-07 |\n",
            "| qf2_loss                | 5.8734463e-07 |\n",
            "| time_elapsed            | 142           |\n",
            "| total timesteps         | 28003         |\n",
            "| value_loss              | 0.00012696872 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007839791   |\n",
            "| ent_coef_loss           | -1.4164119    |\n",
            "| entropy                 | 1.0198689     |\n",
            "| episodes                | 9680          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 27966         |\n",
            "| policy_loss             | -0.55090994   |\n",
            "| qf1_loss                | 1.6391524e-06 |\n",
            "| qf2_loss                | 6.808914e-07  |\n",
            "| time_elapsed            | 142           |\n",
            "| total timesteps         | 28065         |\n",
            "| value_loss              | 9.97335e-05   |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| current_lr              | 0.0003       |\n",
            "| ent_coef                | 0.0078017823 |\n",
            "| ent_coef_loss           | 0.9347394    |\n",
            "| entropy                 | 0.91777986   |\n",
            "| episodes                | 9690         |\n",
            "| fps                     | 197          |\n",
            "| mean 100 episode reward | 0.9          |\n",
            "| n_updates               | 28049        |\n",
            "| policy_loss             | -0.6488556   |\n",
            "| qf1_loss                | 5.852564e-07 |\n",
            "| qf2_loss                | 7.886404e-07 |\n",
            "| time_elapsed            | 142          |\n",
            "| total timesteps         | 28148        |\n",
            "| value_loss              | 7.180655e-05 |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0077912873  |\n",
            "| ent_coef_loss           | 0.7377199     |\n",
            "| entropy                 | 0.9134606     |\n",
            "| episodes                | 9700          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 28112         |\n",
            "| policy_loss             | -0.6347648    |\n",
            "| qf1_loss                | 8.4689054e-07 |\n",
            "| qf2_loss                | 6.506591e-07  |\n",
            "| time_elapsed            | 143           |\n",
            "| total timesteps         | 28211         |\n",
            "| value_loss              | 0.00012021763 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007824784   |\n",
            "| ent_coef_loss           | 0.16364506    |\n",
            "| entropy                 | 0.92235625    |\n",
            "| episodes                | 9710          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 28189         |\n",
            "| policy_loss             | -0.62622935   |\n",
            "| qf1_loss                | 6.370965e-07  |\n",
            "| qf2_loss                | 7.8243187e-07 |\n",
            "| time_elapsed            | 143           |\n",
            "| total timesteps         | 28288         |\n",
            "| value_loss              | 9.059653e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00783116    |\n",
            "| ent_coef_loss           | -2.2006607    |\n",
            "| entropy                 | 0.99221855    |\n",
            "| episodes                | 9720          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 28275         |\n",
            "| policy_loss             | -0.61460507   |\n",
            "| qf1_loss                | 9.510438e-07  |\n",
            "| qf2_loss                | 4.3045202e-07 |\n",
            "| time_elapsed            | 143           |\n",
            "| total timesteps         | 28374         |\n",
            "| value_loss              | 0.00014364108 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00784068    |\n",
            "| ent_coef_loss           | 0.80628383    |\n",
            "| entropy                 | 0.9073293     |\n",
            "| episodes                | 9730          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 28355         |\n",
            "| policy_loss             | -0.63289154   |\n",
            "| qf1_loss                | 9.1234324e-07 |\n",
            "| qf2_loss                | 1.7978095e-06 |\n",
            "| time_elapsed            | 144           |\n",
            "| total timesteps         | 28454         |\n",
            "| value_loss              | 9.816403e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007866325   |\n",
            "| ent_coef_loss           | 1.0053316     |\n",
            "| entropy                 | 0.95952654    |\n",
            "| episodes                | 9740          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 28437         |\n",
            "| policy_loss             | -0.60004586   |\n",
            "| qf1_loss                | 9.2860745e-07 |\n",
            "| qf2_loss                | 2.6344446e-07 |\n",
            "| time_elapsed            | 144           |\n",
            "| total timesteps         | 28536         |\n",
            "| value_loss              | 7.997781e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007926037   |\n",
            "| ent_coef_loss           | 0.7264128     |\n",
            "| entropy                 | 1.0080582     |\n",
            "| episodes                | 9750          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 28510         |\n",
            "| policy_loss             | -0.6198836    |\n",
            "| qf1_loss                | 1.0022734e-06 |\n",
            "| qf2_loss                | 2.7684075e-07 |\n",
            "| time_elapsed            | 144           |\n",
            "| total timesteps         | 28609         |\n",
            "| value_loss              | 0.00012873724 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.00792066     |\n",
            "| ent_coef_loss           | -0.31131315    |\n",
            "| entropy                 | 0.94623613     |\n",
            "| episodes                | 9760           |\n",
            "| fps                     | 197            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 28575          |\n",
            "| policy_loss             | -0.6302139     |\n",
            "| qf1_loss                | 3.5461352e-07  |\n",
            "| qf2_loss                | 2.723949e-06   |\n",
            "| time_elapsed            | 145            |\n",
            "| total timesteps         | 28674          |\n",
            "| value_loss              | 0.000109082335 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007964263   |\n",
            "| ent_coef_loss           | 0.46112132    |\n",
            "| entropy                 | 0.89392555    |\n",
            "| episodes                | 9770          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 28642         |\n",
            "| policy_loss             | -0.6568161    |\n",
            "| qf1_loss                | 2.7679937e-06 |\n",
            "| qf2_loss                | 4.0189568e-07 |\n",
            "| time_elapsed            | 145           |\n",
            "| total timesteps         | 28741         |\n",
            "| value_loss              | 0.00011362819 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.007992877   |\n",
            "| ent_coef_loss           | 0.2667712     |\n",
            "| entropy                 | 0.9504273     |\n",
            "| episodes                | 9780          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 28721         |\n",
            "| policy_loss             | -0.61887586   |\n",
            "| qf1_loss                | 9.241874e-07  |\n",
            "| qf2_loss                | 1.4179537e-06 |\n",
            "| time_elapsed            | 145           |\n",
            "| total timesteps         | 28820         |\n",
            "| value_loss              | 0.0001088494  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008029078   |\n",
            "| ent_coef_loss           | -0.1608775    |\n",
            "| entropy                 | 0.9830791     |\n",
            "| episodes                | 9790          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 28795         |\n",
            "| policy_loss             | -0.62260133   |\n",
            "| qf1_loss                | 1.1494739e-06 |\n",
            "| qf2_loss                | 1.2618339e-06 |\n",
            "| time_elapsed            | 146           |\n",
            "| total timesteps         | 28894         |\n",
            "| value_loss              | 8.225444e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00802206    |\n",
            "| ent_coef_loss           | 1.256839      |\n",
            "| entropy                 | 0.97162586    |\n",
            "| episodes                | 9800          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 28897         |\n",
            "| policy_loss             | -0.6263623    |\n",
            "| qf1_loss                | 8.1640616e-07 |\n",
            "| qf2_loss                | 2.0730565e-07 |\n",
            "| time_elapsed            | 146           |\n",
            "| total timesteps         | 28996         |\n",
            "| value_loss              | 8.2726416e-05 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008084229   |\n",
            "| ent_coef_loss           | -0.22668542   |\n",
            "| entropy                 | 0.9123825     |\n",
            "| episodes                | 9810          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 28972         |\n",
            "| policy_loss             | -0.60862887   |\n",
            "| qf1_loss                | 1.5136987e-06 |\n",
            "| qf2_loss                | 2.2497177e-07 |\n",
            "| time_elapsed            | 147           |\n",
            "| total timesteps         | 29071         |\n",
            "| value_loss              | 0.00012903303 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008122699   |\n",
            "| ent_coef_loss           | 1.9622189     |\n",
            "| entropy                 | 0.8860761     |\n",
            "| episodes                | 9820          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 29058         |\n",
            "| policy_loss             | -0.67863125   |\n",
            "| qf1_loss                | 2.2876445e-06 |\n",
            "| qf2_loss                | 7.4629986e-07 |\n",
            "| time_elapsed            | 147           |\n",
            "| total timesteps         | 29157         |\n",
            "| value_loss              | 0.0001008996  |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008147499    |\n",
            "| ent_coef_loss           | -0.22818935    |\n",
            "| entropy                 | 1.0244706      |\n",
            "| episodes                | 9830           |\n",
            "| fps                     | 197            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 29149          |\n",
            "| policy_loss             | -0.58654016    |\n",
            "| qf1_loss                | 9.3874314e-07  |\n",
            "| qf2_loss                | 3.600499e-07   |\n",
            "| time_elapsed            | 148            |\n",
            "| total timesteps         | 29248          |\n",
            "| value_loss              | 0.000109516084 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008159979   |\n",
            "| ent_coef_loss           | -0.71100295   |\n",
            "| entropy                 | 0.958442      |\n",
            "| episodes                | 9840          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 29233         |\n",
            "| policy_loss             | -0.5909389    |\n",
            "| qf1_loss                | 1.6199381e-06 |\n",
            "| qf2_loss                | 5.8821e-07    |\n",
            "| time_elapsed            | 148           |\n",
            "| total timesteps         | 29332         |\n",
            "| value_loss              | 0.00013345655 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008157022   |\n",
            "| ent_coef_loss           | 1.8795487     |\n",
            "| entropy                 | 0.86511326    |\n",
            "| episodes                | 9850          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 29323         |\n",
            "| policy_loss             | -0.6495131    |\n",
            "| qf1_loss                | 1.1501398e-06 |\n",
            "| qf2_loss                | 3.2330777e-07 |\n",
            "| time_elapsed            | 148           |\n",
            "| total timesteps         | 29422         |\n",
            "| value_loss              | 8.223342e-05  |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008189733    |\n",
            "| ent_coef_loss           | 0.20733953     |\n",
            "| entropy                 | 0.91971433     |\n",
            "| episodes                | 9860           |\n",
            "| fps                     | 197            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 29415          |\n",
            "| policy_loss             | -0.60207695    |\n",
            "| qf1_loss                | 2.973986e-06   |\n",
            "| qf2_loss                | 5.409129e-07   |\n",
            "| time_elapsed            | 149            |\n",
            "| total timesteps         | 29514          |\n",
            "| value_loss              | 0.000108270906 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008140749   |\n",
            "| ent_coef_loss           | -0.82959384   |\n",
            "| entropy                 | 0.989373      |\n",
            "| episodes                | 9870          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 29493         |\n",
            "| policy_loss             | -0.58263034   |\n",
            "| qf1_loss                | 1.0200313e-06 |\n",
            "| qf2_loss                | 7.1056576e-07 |\n",
            "| time_elapsed            | 149           |\n",
            "| total timesteps         | 29592         |\n",
            "| value_loss              | 0.00015478075 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008128841   |\n",
            "| ent_coef_loss           | 0.2558694     |\n",
            "| entropy                 | 0.9524616     |\n",
            "| episodes                | 9880          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 29576         |\n",
            "| policy_loss             | -0.6032164    |\n",
            "| qf1_loss                | 1.6283711e-06 |\n",
            "| qf2_loss                | 1.6031532e-07 |\n",
            "| time_elapsed            | 150           |\n",
            "| total timesteps         | 29675         |\n",
            "| value_loss              | 0.00010085899 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008072758   |\n",
            "| ent_coef_loss           | -1.1049789    |\n",
            "| entropy                 | 0.9865403     |\n",
            "| episodes                | 9890          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 29685         |\n",
            "| policy_loss             | -0.5789876    |\n",
            "| qf1_loss                | 1.0269297e-06 |\n",
            "| qf2_loss                | 9.005752e-07  |\n",
            "| time_elapsed            | 150           |\n",
            "| total timesteps         | 29784         |\n",
            "| value_loss              | 0.00011427957 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.0080523435   |\n",
            "| ent_coef_loss           | -0.5919795     |\n",
            "| entropy                 | 0.9461701      |\n",
            "| episodes                | 9900           |\n",
            "| fps                     | 197            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 29769          |\n",
            "| policy_loss             | -0.5845165     |\n",
            "| qf1_loss                | 1.9317902e-06  |\n",
            "| qf2_loss                | 3.319396e-07   |\n",
            "| time_elapsed            | 150            |\n",
            "| total timesteps         | 29868          |\n",
            "| value_loss              | 0.000110500754 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0080733     |\n",
            "| ent_coef_loss           | 0.5207275     |\n",
            "| entropy                 | 0.9043168     |\n",
            "| episodes                | 9910          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 29845         |\n",
            "| policy_loss             | -0.62907803   |\n",
            "| qf1_loss                | 2.2352574e-06 |\n",
            "| qf2_loss                | 1.9923214e-06 |\n",
            "| time_elapsed            | 151           |\n",
            "| total timesteps         | 29944         |\n",
            "| value_loss              | 0.00011460121 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008082587   |\n",
            "| ent_coef_loss           | -1.6432966    |\n",
            "| entropy                 | 0.9508832     |\n",
            "| episodes                | 9920          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 29933         |\n",
            "| policy_loss             | -0.6046643    |\n",
            "| qf1_loss                | 2.147386e-06  |\n",
            "| qf2_loss                | 3.3512381e-07 |\n",
            "| time_elapsed            | 151           |\n",
            "| total timesteps         | 30032         |\n",
            "| value_loss              | 8.878251e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008065489   |\n",
            "| ent_coef_loss           | 0.64615726    |\n",
            "| entropy                 | 0.94390136    |\n",
            "| episodes                | 9930          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 30027         |\n",
            "| policy_loss             | -0.5961425    |\n",
            "| qf1_loss                | 1.6371042e-06 |\n",
            "| qf2_loss                | 1.5510391e-06 |\n",
            "| time_elapsed            | 152           |\n",
            "| total timesteps         | 30126         |\n",
            "| value_loss              | 0.00011803266 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008115085   |\n",
            "| ent_coef_loss           | -1.0916753    |\n",
            "| entropy                 | 0.9255216     |\n",
            "| episodes                | 9940          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 30115         |\n",
            "| policy_loss             | -0.627669     |\n",
            "| qf1_loss                | 2.7090205e-06 |\n",
            "| qf2_loss                | 2.0469227e-07 |\n",
            "| time_elapsed            | 152           |\n",
            "| total timesteps         | 30214         |\n",
            "| value_loss              | 0.00015379279 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008117523   |\n",
            "| ent_coef_loss           | 0.56337863    |\n",
            "| entropy                 | 0.86506003    |\n",
            "| episodes                | 9950          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 30206         |\n",
            "| policy_loss             | -0.6292897    |\n",
            "| qf1_loss                | 9.4606816e-07 |\n",
            "| qf2_loss                | 3.4983668e-07 |\n",
            "| time_elapsed            | 153           |\n",
            "| total timesteps         | 30305         |\n",
            "| value_loss              | 6.396504e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008163046   |\n",
            "| ent_coef_loss           | 0.8258766     |\n",
            "| entropy                 | 0.9504672     |\n",
            "| episodes                | 9960          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 30268         |\n",
            "| policy_loss             | -0.59452283   |\n",
            "| qf1_loss                | 7.773699e-07  |\n",
            "| qf2_loss                | 4.3970746e-07 |\n",
            "| time_elapsed            | 153           |\n",
            "| total timesteps         | 30367         |\n",
            "| value_loss              | 0.00013503607 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008279427   |\n",
            "| ent_coef_loss           | -0.18305346   |\n",
            "| entropy                 | 0.9580182     |\n",
            "| episodes                | 9970          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 30371         |\n",
            "| policy_loss             | -0.57322884   |\n",
            "| qf1_loss                | 1.9708036e-06 |\n",
            "| qf2_loss                | 2.1051233e-06 |\n",
            "| time_elapsed            | 154           |\n",
            "| total timesteps         | 30470         |\n",
            "| value_loss              | 8.7099805e-05 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008287109   |\n",
            "| ent_coef_loss           | -0.27054498   |\n",
            "| entropy                 | 0.9206022     |\n",
            "| episodes                | 9980          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 30466         |\n",
            "| policy_loss             | -0.6362437    |\n",
            "| qf1_loss                | 1.1618681e-06 |\n",
            "| qf2_loss                | 1.4748566e-06 |\n",
            "| time_elapsed            | 154           |\n",
            "| total timesteps         | 30565         |\n",
            "| value_loss              | 0.00014072345 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008236883   |\n",
            "| ent_coef_loss           | -0.3123406    |\n",
            "| entropy                 | 0.93406945    |\n",
            "| episodes                | 9990          |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 30546         |\n",
            "| policy_loss             | -0.6070132    |\n",
            "| qf1_loss                | 1.3359299e-06 |\n",
            "| qf2_loss                | 6.388749e-07  |\n",
            "| time_elapsed            | 155           |\n",
            "| total timesteps         | 30645         |\n",
            "| value_loss              | 0.00010970523 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008255434   |\n",
            "| ent_coef_loss           | 1.54547       |\n",
            "| entropy                 | 0.8460586     |\n",
            "| episodes                | 10000         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 30629         |\n",
            "| policy_loss             | -0.66600645   |\n",
            "| qf1_loss                | 1.1807006e-06 |\n",
            "| qf2_loss                | 3.3082807e-07 |\n",
            "| time_elapsed            | 155           |\n",
            "| total timesteps         | 30728         |\n",
            "| value_loss              | 0.00013175872 |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| current_lr              | 0.0003       |\n",
            "| ent_coef                | 0.008265664  |\n",
            "| ent_coef_loss           | 1.2194624    |\n",
            "| entropy                 | 0.89006376   |\n",
            "| episodes                | 10010        |\n",
            "| fps                     | 197          |\n",
            "| mean 100 episode reward | 0.9          |\n",
            "| n_updates               | 30719        |\n",
            "| policy_loss             | -0.64766484  |\n",
            "| qf1_loss                | 6.963893e-07 |\n",
            "| qf2_loss                | 8.116681e-07 |\n",
            "| time_elapsed            | 156          |\n",
            "| total timesteps         | 30818        |\n",
            "| value_loss              | 8.760497e-05 |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008243209   |\n",
            "| ent_coef_loss           | -0.43575388   |\n",
            "| entropy                 | 0.91427755    |\n",
            "| episodes                | 10020         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 30797         |\n",
            "| policy_loss             | -0.6478484    |\n",
            "| qf1_loss                | 1.3845024e-06 |\n",
            "| qf2_loss                | 4.7582392e-07 |\n",
            "| time_elapsed            | 156           |\n",
            "| total timesteps         | 30896         |\n",
            "| value_loss              | 0.00013993499 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008292603   |\n",
            "| ent_coef_loss           | 0.72883976    |\n",
            "| entropy                 | 0.9415308     |\n",
            "| episodes                | 10030         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 30901         |\n",
            "| policy_loss             | -0.6246501    |\n",
            "| qf1_loss                | 2.3043208e-06 |\n",
            "| qf2_loss                | 2.6253729e-06 |\n",
            "| time_elapsed            | 157           |\n",
            "| total timesteps         | 31000         |\n",
            "| value_loss              | 0.00014076161 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0082799     |\n",
            "| ent_coef_loss           | -0.5914706    |\n",
            "| entropy                 | 0.9245602     |\n",
            "| episodes                | 10040         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 30985         |\n",
            "| policy_loss             | -0.6451287    |\n",
            "| qf1_loss                | 1.5152359e-06 |\n",
            "| qf2_loss                | 1.1075783e-06 |\n",
            "| time_elapsed            | 157           |\n",
            "| total timesteps         | 31084         |\n",
            "| value_loss              | 0.00012731919 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008284245   |\n",
            "| ent_coef_loss           | 0.09262701    |\n",
            "| entropy                 | 0.89833295    |\n",
            "| episodes                | 10050         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 31055         |\n",
            "| policy_loss             | -0.62257624   |\n",
            "| qf1_loss                | 1.3350409e-06 |\n",
            "| qf2_loss                | 4.9774917e-07 |\n",
            "| time_elapsed            | 157           |\n",
            "| total timesteps         | 31154         |\n",
            "| value_loss              | 8.7325876e-05 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008259608   |\n",
            "| ent_coef_loss           | 0.64795345    |\n",
            "| entropy                 | 0.92638       |\n",
            "| episodes                | 10060         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 31124         |\n",
            "| policy_loss             | -0.6263623    |\n",
            "| qf1_loss                | 8.272447e-07  |\n",
            "| qf2_loss                | 1.3871978e-06 |\n",
            "| time_elapsed            | 158           |\n",
            "| total timesteps         | 31223         |\n",
            "| value_loss              | 0.00021718303 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008271649   |\n",
            "| ent_coef_loss           | 0.33451444    |\n",
            "| entropy                 | 0.9376006     |\n",
            "| episodes                | 10070         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 31223         |\n",
            "| policy_loss             | -0.6321154    |\n",
            "| qf1_loss                | 6.380714e-07  |\n",
            "| qf2_loss                | 3.1863033e-07 |\n",
            "| time_elapsed            | 158           |\n",
            "| total timesteps         | 31322         |\n",
            "| value_loss              | 8.178207e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008307279   |\n",
            "| ent_coef_loss           | -0.3831071    |\n",
            "| entropy                 | 0.88279355    |\n",
            "| episodes                | 10080         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 31308         |\n",
            "| policy_loss             | -0.6165776    |\n",
            "| qf1_loss                | 1.213809e-06  |\n",
            "| qf2_loss                | 2.5863915e-07 |\n",
            "| time_elapsed            | 159           |\n",
            "| total timesteps         | 31407         |\n",
            "| value_loss              | 0.00017001943 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008345047   |\n",
            "| ent_coef_loss           | -1.1321318    |\n",
            "| entropy                 | 0.9690673     |\n",
            "| episodes                | 10090         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 31390         |\n",
            "| policy_loss             | -0.5876164    |\n",
            "| qf1_loss                | 1.2046293e-06 |\n",
            "| qf2_loss                | 6.4098265e-07 |\n",
            "| time_elapsed            | 159           |\n",
            "| total timesteps         | 31489         |\n",
            "| value_loss              | 0.00011411108 |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| current_lr              | 0.0003       |\n",
            "| ent_coef                | 0.008359524  |\n",
            "| ent_coef_loss           | 0.14742282   |\n",
            "| entropy                 | 0.8674449    |\n",
            "| episodes                | 10100        |\n",
            "| fps                     | 197          |\n",
            "| mean 100 episode reward | 0.9          |\n",
            "| n_updates               | 31479        |\n",
            "| policy_loss             | -0.6094043   |\n",
            "| qf1_loss                | 7.124331e-07 |\n",
            "| qf2_loss                | 2.028723e-06 |\n",
            "| time_elapsed            | 159          |\n",
            "| total timesteps         | 31578        |\n",
            "| value_loss              | 9.027889e-05 |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008426583   |\n",
            "| ent_coef_loss           | -1.6959134    |\n",
            "| entropy                 | 0.9769898     |\n",
            "| episodes                | 10110         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 31555         |\n",
            "| policy_loss             | -0.58257246   |\n",
            "| qf1_loss                | 9.410014e-07  |\n",
            "| qf2_loss                | 3.0879852e-07 |\n",
            "| time_elapsed            | 160           |\n",
            "| total timesteps         | 31654         |\n",
            "| value_loss              | 0.00012317028 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008465908    |\n",
            "| ent_coef_loss           | 0.9491365      |\n",
            "| entropy                 | 0.8267824      |\n",
            "| episodes                | 10120          |\n",
            "| fps                     | 197            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 31660          |\n",
            "| policy_loss             | -0.6078399     |\n",
            "| qf1_loss                | 9.307303e-07   |\n",
            "| qf2_loss                | 2.0901165e-07  |\n",
            "| time_elapsed            | 160            |\n",
            "| total timesteps         | 31759          |\n",
            "| value_loss              | 0.000116434894 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0085712215  |\n",
            "| ent_coef_loss           | 0.13960195    |\n",
            "| entropy                 | 0.988088      |\n",
            "| episodes                | 10130         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 31750         |\n",
            "| policy_loss             | -0.5883877    |\n",
            "| qf1_loss                | 9.925122e-07  |\n",
            "| qf2_loss                | 9.38208e-07   |\n",
            "| time_elapsed            | 161           |\n",
            "| total timesteps         | 31849         |\n",
            "| value_loss              | 0.00018671676 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008572006   |\n",
            "| ent_coef_loss           | 0.57998097    |\n",
            "| entropy                 | 0.89677614    |\n",
            "| episodes                | 10140         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 31810         |\n",
            "| policy_loss             | -0.6358869    |\n",
            "| qf1_loss                | 1.6382959e-06 |\n",
            "| qf2_loss                | 5.61463e-07   |\n",
            "| time_elapsed            | 161           |\n",
            "| total timesteps         | 31909         |\n",
            "| value_loss              | 7.8994766e-05 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008613803   |\n",
            "| ent_coef_loss           | 0.015938938   |\n",
            "| entropy                 | 0.91656876    |\n",
            "| episodes                | 10150         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 31915         |\n",
            "| policy_loss             | -0.6198057    |\n",
            "| qf1_loss                | 1.8218332e-06 |\n",
            "| qf2_loss                | 4.935123e-07  |\n",
            "| time_elapsed            | 161           |\n",
            "| total timesteps         | 32014         |\n",
            "| value_loss              | 0.00013051773 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008591066   |\n",
            "| ent_coef_loss           | -0.294256     |\n",
            "| entropy                 | 0.90151083    |\n",
            "| episodes                | 10160         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 31992         |\n",
            "| policy_loss             | -0.6356437    |\n",
            "| qf1_loss                | 1.0563917e-06 |\n",
            "| qf2_loss                | 8.109856e-07  |\n",
            "| time_elapsed            | 162           |\n",
            "| total timesteps         | 32091         |\n",
            "| value_loss              | 8.872256e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00860053    |\n",
            "| ent_coef_loss           | 0.44110057    |\n",
            "| entropy                 | 0.8371496     |\n",
            "| episodes                | 10170         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 32066         |\n",
            "| policy_loss             | -0.65324086   |\n",
            "| qf1_loss                | 9.779219e-07  |\n",
            "| qf2_loss                | 3.8596147e-07 |\n",
            "| time_elapsed            | 162           |\n",
            "| total timesteps         | 32165         |\n",
            "| value_loss              | 0.0001607717  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0086346455  |\n",
            "| ent_coef_loss           | 0.5520727     |\n",
            "| entropy                 | 0.82977295    |\n",
            "| episodes                | 10180         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 32143         |\n",
            "| policy_loss             | -0.64395916   |\n",
            "| qf1_loss                | 5.532107e-07  |\n",
            "| qf2_loss                | 6.210722e-07  |\n",
            "| time_elapsed            | 163           |\n",
            "| total timesteps         | 32242         |\n",
            "| value_loss              | 0.00010171689 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008676856    |\n",
            "| ent_coef_loss           | 0.77345115     |\n",
            "| entropy                 | 0.937093       |\n",
            "| episodes                | 10190          |\n",
            "| fps                     | 197            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 32230          |\n",
            "| policy_loss             | -0.57532865    |\n",
            "| qf1_loss                | 1.6300758e-06  |\n",
            "| qf2_loss                | 2.0308292e-07  |\n",
            "| time_elapsed            | 163            |\n",
            "| total timesteps         | 32329          |\n",
            "| value_loss              | 0.000112406065 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008740748   |\n",
            "| ent_coef_loss           | -0.7790238    |\n",
            "| entropy                 | 1.0340085     |\n",
            "| episodes                | 10200         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 32316         |\n",
            "| policy_loss             | -0.558486     |\n",
            "| qf1_loss                | 5.5760574e-07 |\n",
            "| qf2_loss                | 2.6225393e-07 |\n",
            "| time_elapsed            | 163           |\n",
            "| total timesteps         | 32415         |\n",
            "| value_loss              | 0.00012937986 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0086954525  |\n",
            "| ent_coef_loss           | 0.42782065    |\n",
            "| entropy                 | 0.8523104     |\n",
            "| episodes                | 10210         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 32413         |\n",
            "| policy_loss             | -0.64494485   |\n",
            "| qf1_loss                | 2.5007735e-06 |\n",
            "| qf2_loss                | 3.1756414e-07 |\n",
            "| time_elapsed            | 164           |\n",
            "| total timesteps         | 32512         |\n",
            "| value_loss              | 8.913029e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008667485   |\n",
            "| ent_coef_loss           | -1.2944732    |\n",
            "| entropy                 | 0.9573816     |\n",
            "| episodes                | 10220         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 32494         |\n",
            "| policy_loss             | -0.58862656   |\n",
            "| qf1_loss                | 8.1469955e-07 |\n",
            "| qf2_loss                | 1.2097224e-06 |\n",
            "| time_elapsed            | 164           |\n",
            "| total timesteps         | 32593         |\n",
            "| value_loss              | 0.00020157863 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00861965    |\n",
            "| ent_coef_loss           | -0.65306497   |\n",
            "| entropy                 | 0.9714283     |\n",
            "| episodes                | 10230         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 32556         |\n",
            "| policy_loss             | -0.6014963    |\n",
            "| qf1_loss                | 8.3115276e-07 |\n",
            "| qf2_loss                | 3.9442037e-07 |\n",
            "| time_elapsed            | 165           |\n",
            "| total timesteps         | 32655         |\n",
            "| value_loss              | 0.00015549813 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008577113   |\n",
            "| ent_coef_loss           | 0.20073873    |\n",
            "| entropy                 | 0.8436195     |\n",
            "| episodes                | 10240         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 32637         |\n",
            "| policy_loss             | -0.653597     |\n",
            "| qf1_loss                | 9.877717e-07  |\n",
            "| qf2_loss                | 3.3839825e-07 |\n",
            "| time_elapsed            | 165           |\n",
            "| total timesteps         | 32736         |\n",
            "| value_loss              | 0.00014173606 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00856426    |\n",
            "| ent_coef_loss           | 1.0274222     |\n",
            "| entropy                 | 0.8958316     |\n",
            "| episodes                | 10250         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 32724         |\n",
            "| policy_loss             | -0.6297973    |\n",
            "| qf1_loss                | 6.3326513e-07 |\n",
            "| qf2_loss                | 3.4548367e-07 |\n",
            "| time_elapsed            | 165           |\n",
            "| total timesteps         | 32823         |\n",
            "| value_loss              | 0.00010050629 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008597525   |\n",
            "| ent_coef_loss           | 0.2834232     |\n",
            "| entropy                 | 0.8854702     |\n",
            "| episodes                | 10260         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 32799         |\n",
            "| policy_loss             | -0.60789305   |\n",
            "| qf1_loss                | 8.7403146e-07 |\n",
            "| qf2_loss                | 3.5275434e-06 |\n",
            "| time_elapsed            | 166           |\n",
            "| total timesteps         | 32898         |\n",
            "| value_loss              | 0.00011927778 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008582824   |\n",
            "| ent_coef_loss           | 0.2908697     |\n",
            "| entropy                 | 0.9257136     |\n",
            "| episodes                | 10270         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 32881         |\n",
            "| policy_loss             | -0.5938525    |\n",
            "| qf1_loss                | 1.2530948e-06 |\n",
            "| qf2_loss                | 1.2215467e-06 |\n",
            "| time_elapsed            | 166           |\n",
            "| total timesteps         | 32980         |\n",
            "| value_loss              | 0.00012605832 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008617398   |\n",
            "| ent_coef_loss           | 0.86558557    |\n",
            "| entropy                 | 0.88988394    |\n",
            "| episodes                | 10280         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 32950         |\n",
            "| policy_loss             | -0.61731696   |\n",
            "| qf1_loss                | 8.235596e-07  |\n",
            "| qf2_loss                | 2.0826982e-07 |\n",
            "| time_elapsed            | 167           |\n",
            "| total timesteps         | 33049         |\n",
            "| value_loss              | 7.7773584e-05 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008603181   |\n",
            "| ent_coef_loss           | -0.12069261   |\n",
            "| entropy                 | 0.8668039     |\n",
            "| episodes                | 10290         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 33028         |\n",
            "| policy_loss             | -0.64040256   |\n",
            "| qf1_loss                | 7.3372297e-07 |\n",
            "| qf2_loss                | 2.1766277e-07 |\n",
            "| time_elapsed            | 167           |\n",
            "| total timesteps         | 33127         |\n",
            "| value_loss              | 0.00014014327 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008592242   |\n",
            "| ent_coef_loss           | -0.18407667   |\n",
            "| entropy                 | 0.91409814    |\n",
            "| episodes                | 10300         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 33099         |\n",
            "| policy_loss             | -0.6505897    |\n",
            "| qf1_loss                | 6.0722857e-07 |\n",
            "| qf2_loss                | 3.4471003e-07 |\n",
            "| time_elapsed            | 167           |\n",
            "| total timesteps         | 33198         |\n",
            "| value_loss              | 0.0001199139  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008519935   |\n",
            "| ent_coef_loss           | -0.926212     |\n",
            "| entropy                 | 0.97302085    |\n",
            "| episodes                | 10310         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 33151         |\n",
            "| policy_loss             | -0.5862164    |\n",
            "| qf1_loss                | 3.408663e-06  |\n",
            "| qf2_loss                | 4.286465e-07  |\n",
            "| time_elapsed            | 167           |\n",
            "| total timesteps         | 33250         |\n",
            "| value_loss              | 0.00013876698 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00849231    |\n",
            "| ent_coef_loss           | -0.17518254   |\n",
            "| entropy                 | 0.9280608     |\n",
            "| episodes                | 10320         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 33253         |\n",
            "| policy_loss             | -0.63215804   |\n",
            "| qf1_loss                | 1.6467122e-06 |\n",
            "| qf2_loss                | 1.6514842e-06 |\n",
            "| time_elapsed            | 168           |\n",
            "| total timesteps         | 33352         |\n",
            "| value_loss              | 0.00012718653 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008486727   |\n",
            "| ent_coef_loss           | -1.0238792    |\n",
            "| entropy                 | 1.0302708     |\n",
            "| episodes                | 10330         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 33313         |\n",
            "| policy_loss             | -0.61005026   |\n",
            "| qf1_loss                | 7.8487756e-07 |\n",
            "| qf2_loss                | 5.592261e-07  |\n",
            "| time_elapsed            | 168           |\n",
            "| total timesteps         | 33412         |\n",
            "| value_loss              | 0.00016708593 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008441218   |\n",
            "| ent_coef_loss           | -0.5389309    |\n",
            "| entropy                 | 0.9915127     |\n",
            "| episodes                | 10340         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 33377         |\n",
            "| policy_loss             | -0.59038293   |\n",
            "| qf1_loss                | 1.1393697e-06 |\n",
            "| qf2_loss                | 5.338025e-07  |\n",
            "| time_elapsed            | 169           |\n",
            "| total timesteps         | 33476         |\n",
            "| value_loss              | 9.973787e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008437126   |\n",
            "| ent_coef_loss           | 0.9022708     |\n",
            "| entropy                 | 0.9482859     |\n",
            "| episodes                | 10350         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 33451         |\n",
            "| policy_loss             | -0.61805606   |\n",
            "| qf1_loss                | 3.3672445e-06 |\n",
            "| qf2_loss                | 7.5462674e-07 |\n",
            "| time_elapsed            | 169           |\n",
            "| total timesteps         | 33550         |\n",
            "| value_loss              | 0.00015584273 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008415622   |\n",
            "| ent_coef_loss           | 0.32401466    |\n",
            "| entropy                 | 0.98128176    |\n",
            "| episodes                | 10360         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 33544         |\n",
            "| policy_loss             | -0.60165715   |\n",
            "| qf1_loss                | 9.974108e-07  |\n",
            "| qf2_loss                | 1.919351e-07  |\n",
            "| time_elapsed            | 169           |\n",
            "| total timesteps         | 33643         |\n",
            "| value_loss              | 0.00011633639 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008407627   |\n",
            "| ent_coef_loss           | -1.2119365    |\n",
            "| entropy                 | 0.96636504    |\n",
            "| episodes                | 10370         |\n",
            "| fps                     | 197           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 33614         |\n",
            "| policy_loss             | -0.5868118    |\n",
            "| qf1_loss                | 2.9338623e-06 |\n",
            "| qf2_loss                | 2.8510584e-07 |\n",
            "| time_elapsed            | 170           |\n",
            "| total timesteps         | 33713         |\n",
            "| value_loss              | 0.00014351745 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.00839973     |\n",
            "| ent_coef_loss           | 0.64445025     |\n",
            "| entropy                 | 0.8659483      |\n",
            "| episodes                | 10380          |\n",
            "| fps                     | 198            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 33693          |\n",
            "| policy_loss             | -0.64102936    |\n",
            "| qf1_loss                | 6.0806315e-07  |\n",
            "| qf2_loss                | 1.4487514e-06  |\n",
            "| time_elapsed            | 170            |\n",
            "| total timesteps         | 33792          |\n",
            "| value_loss              | 0.000109535045 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008424579   |\n",
            "| ent_coef_loss           | 0.5248059     |\n",
            "| entropy                 | 0.89678764    |\n",
            "| episodes                | 10390         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 33787         |\n",
            "| policy_loss             | -0.6201743    |\n",
            "| qf1_loss                | 1.0137564e-06 |\n",
            "| qf2_loss                | 1.7622973e-07 |\n",
            "| time_elapsed            | 171           |\n",
            "| total timesteps         | 33886         |\n",
            "| value_loss              | 8.088212e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00845883    |\n",
            "| ent_coef_loss           | -0.7245128    |\n",
            "| entropy                 | 0.96831226    |\n",
            "| episodes                | 10400         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 33867         |\n",
            "| policy_loss             | -0.5990114    |\n",
            "| qf1_loss                | 1.5198034e-06 |\n",
            "| qf2_loss                | 3.0732758e-07 |\n",
            "| time_elapsed            | 171           |\n",
            "| total timesteps         | 33966         |\n",
            "| value_loss              | 0.00011251299 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008436755   |\n",
            "| ent_coef_loss           | 0.18692282    |\n",
            "| entropy                 | 0.9278012     |\n",
            "| episodes                | 10410         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 33933         |\n",
            "| policy_loss             | -0.60453594   |\n",
            "| qf1_loss                | 1.4256645e-06 |\n",
            "| qf2_loss                | 1.297258e-06  |\n",
            "| time_elapsed            | 171           |\n",
            "| total timesteps         | 34032         |\n",
            "| value_loss              | 9.915215e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008428902   |\n",
            "| ent_coef_loss           | 0.17981791    |\n",
            "| entropy                 | 0.9376325     |\n",
            "| episodes                | 10420         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 34001         |\n",
            "| policy_loss             | -0.5971519    |\n",
            "| qf1_loss                | 1.1793124e-06 |\n",
            "| qf2_loss                | 7.3398195e-07 |\n",
            "| time_elapsed            | 172           |\n",
            "| total timesteps         | 34100         |\n",
            "| value_loss              | 9.682344e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008528825   |\n",
            "| ent_coef_loss           | 0.24588853    |\n",
            "| entropy                 | 0.89290905    |\n",
            "| episodes                | 10430         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 34105         |\n",
            "| policy_loss             | -0.610781     |\n",
            "| qf1_loss                | 9.168449e-07  |\n",
            "| qf2_loss                | 3.6507285e-07 |\n",
            "| time_elapsed            | 172           |\n",
            "| total timesteps         | 34204         |\n",
            "| value_loss              | 0.0001532241  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008549729   |\n",
            "| ent_coef_loss           | 0.8121568     |\n",
            "| entropy                 | 0.8808468     |\n",
            "| episodes                | 10440         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 34206         |\n",
            "| policy_loss             | -0.622487     |\n",
            "| qf1_loss                | 5.3623125e-07 |\n",
            "| qf2_loss                | 4.5138196e-07 |\n",
            "| time_elapsed            | 173           |\n",
            "| total timesteps         | 34305         |\n",
            "| value_loss              | 0.00012933121 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008523186   |\n",
            "| ent_coef_loss           | -0.38600597   |\n",
            "| entropy                 | 0.98255515    |\n",
            "| episodes                | 10450         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 34297         |\n",
            "| policy_loss             | -0.6069354    |\n",
            "| qf1_loss                | 3.8258244e-07 |\n",
            "| qf2_loss                | 1.531793e-06  |\n",
            "| time_elapsed            | 173           |\n",
            "| total timesteps         | 34396         |\n",
            "| value_loss              | 0.0001279151  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00854048    |\n",
            "| ent_coef_loss           | -0.537816     |\n",
            "| entropy                 | 1.0379004     |\n",
            "| episodes                | 10460         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 34364         |\n",
            "| policy_loss             | -0.53819674   |\n",
            "| qf1_loss                | 1.1446082e-06 |\n",
            "| qf2_loss                | 8.5485107e-07 |\n",
            "| time_elapsed            | 173           |\n",
            "| total timesteps         | 34463         |\n",
            "| value_loss              | 0.00012142652 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008556615   |\n",
            "| ent_coef_loss           | -0.32997468   |\n",
            "| entropy                 | 1.0004567     |\n",
            "| episodes                | 10470         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 34451         |\n",
            "| policy_loss             | -0.5644733    |\n",
            "| qf1_loss                | 6.4601534e-07 |\n",
            "| qf2_loss                | 1.9037138e-06 |\n",
            "| time_elapsed            | 174           |\n",
            "| total timesteps         | 34550         |\n",
            "| value_loss              | 0.00014951278 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008580062   |\n",
            "| ent_coef_loss           | -0.08225852   |\n",
            "| entropy                 | 0.9524463     |\n",
            "| episodes                | 10480         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 34552         |\n",
            "| policy_loss             | -0.60924387   |\n",
            "| qf1_loss                | 7.539531e-07  |\n",
            "| qf2_loss                | 3.7102956e-07 |\n",
            "| time_elapsed            | 174           |\n",
            "| total timesteps         | 34651         |\n",
            "| value_loss              | 0.00011346815 |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| current_lr              | 0.0003       |\n",
            "| ent_coef                | 0.008657638  |\n",
            "| ent_coef_loss           | 1.0107706    |\n",
            "| entropy                 | 0.86470866   |\n",
            "| episodes                | 10490        |\n",
            "| fps                     | 198          |\n",
            "| mean 100 episode reward | 0.9          |\n",
            "| n_updates               | 34653        |\n",
            "| policy_loss             | -0.60334694  |\n",
            "| qf1_loss                | 1.253688e-06 |\n",
            "| qf2_loss                | 7.337859e-07 |\n",
            "| time_elapsed            | 175          |\n",
            "| total timesteps         | 34752        |\n",
            "| value_loss              | 7.582137e-05 |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008710508   |\n",
            "| ent_coef_loss           | -0.4017778    |\n",
            "| entropy                 | 1.0089352     |\n",
            "| episodes                | 10500         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 34756         |\n",
            "| policy_loss             | -0.5819918    |\n",
            "| qf1_loss                | 1.0482265e-06 |\n",
            "| qf2_loss                | 1.4846935e-07 |\n",
            "| time_elapsed            | 175           |\n",
            "| total timesteps         | 34855         |\n",
            "| value_loss              | 0.00012270026 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0087152785  |\n",
            "| ent_coef_loss           | -0.33391836   |\n",
            "| entropy                 | 0.88737345    |\n",
            "| episodes                | 10510         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 34827         |\n",
            "| policy_loss             | -0.61415213   |\n",
            "| qf1_loss                | 8.848356e-07  |\n",
            "| qf2_loss                | 3.1505667e-07 |\n",
            "| time_elapsed            | 176           |\n",
            "| total timesteps         | 34926         |\n",
            "| value_loss              | 0.00013473534 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008695163   |\n",
            "| ent_coef_loss           | -0.31135377   |\n",
            "| entropy                 | 0.953936      |\n",
            "| episodes                | 10520         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 34918         |\n",
            "| policy_loss             | -0.64282084   |\n",
            "| qf1_loss                | 9.702572e-07  |\n",
            "| qf2_loss                | 4.1079983e-07 |\n",
            "| time_elapsed            | 176           |\n",
            "| total timesteps         | 35017         |\n",
            "| value_loss              | 0.00015292363 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008686845   |\n",
            "| ent_coef_loss           | 0.014024556   |\n",
            "| entropy                 | 0.9018686     |\n",
            "| episodes                | 10530         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 35004         |\n",
            "| policy_loss             | -0.6513168    |\n",
            "| qf1_loss                | 1.1787391e-06 |\n",
            "| qf2_loss                | 2.557997e-07  |\n",
            "| time_elapsed            | 176           |\n",
            "| total timesteps         | 35103         |\n",
            "| value_loss              | 0.00013332351 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008620785   |\n",
            "| ent_coef_loss           | 0.45701012    |\n",
            "| entropy                 | 0.90012866    |\n",
            "| episodes                | 10540         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 35107         |\n",
            "| policy_loss             | -0.63965225   |\n",
            "| qf1_loss                | 7.289177e-07  |\n",
            "| qf2_loss                | 2.1263921e-07 |\n",
            "| time_elapsed            | 177           |\n",
            "| total timesteps         | 35206         |\n",
            "| value_loss              | 0.00010652662 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008606212   |\n",
            "| ent_coef_loss           | 0.19322081    |\n",
            "| entropy                 | 0.9280457     |\n",
            "| episodes                | 10550         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 35204         |\n",
            "| policy_loss             | -0.594956     |\n",
            "| qf1_loss                | 1.0591868e-06 |\n",
            "| qf2_loss                | 1.020606e-06  |\n",
            "| time_elapsed            | 177           |\n",
            "| total timesteps         | 35303         |\n",
            "| value_loss              | 0.00012879632 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008581842    |\n",
            "| ent_coef_loss           | 1.5891382      |\n",
            "| entropy                 | 0.9731531      |\n",
            "| episodes                | 10560          |\n",
            "| fps                     | 198            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 35267          |\n",
            "| policy_loss             | -0.617535      |\n",
            "| qf1_loss                | 1.6603184e-06  |\n",
            "| qf2_loss                | 6.5520186e-07  |\n",
            "| time_elapsed            | 178            |\n",
            "| total timesteps         | 35366          |\n",
            "| value_loss              | 0.000116320545 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008553767   |\n",
            "| ent_coef_loss           | 0.1748863     |\n",
            "| entropy                 | 0.9111931     |\n",
            "| episodes                | 10570         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 35364         |\n",
            "| policy_loss             | -0.62717766   |\n",
            "| qf1_loss                | 6.777047e-07  |\n",
            "| qf2_loss                | 2.5326645e-07 |\n",
            "| time_elapsed            | 178           |\n",
            "| total timesteps         | 35463         |\n",
            "| value_loss              | 8.7282664e-05 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008507042   |\n",
            "| ent_coef_loss           | 0.07166946    |\n",
            "| entropy                 | 0.89530826    |\n",
            "| episodes                | 10580         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 35470         |\n",
            "| policy_loss             | -0.6427763    |\n",
            "| qf1_loss                | 8.878126e-07  |\n",
            "| qf2_loss                | 1.405131e-07  |\n",
            "| time_elapsed            | 179           |\n",
            "| total timesteps         | 35569         |\n",
            "| value_loss              | 9.9159945e-05 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008498945   |\n",
            "| ent_coef_loss           | -0.013841271  |\n",
            "| entropy                 | 0.92642194    |\n",
            "| episodes                | 10590         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 35591         |\n",
            "| policy_loss             | -0.6078233    |\n",
            "| qf1_loss                | 1.3280862e-06 |\n",
            "| qf2_loss                | 7.563651e-07  |\n",
            "| time_elapsed            | 179           |\n",
            "| total timesteps         | 35690         |\n",
            "| value_loss              | 0.0001344083  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008554342   |\n",
            "| ent_coef_loss           | -0.17381868   |\n",
            "| entropy                 | 0.9835502     |\n",
            "| episodes                | 10600         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 35677         |\n",
            "| policy_loss             | -0.6308032    |\n",
            "| qf1_loss                | 5.961482e-07  |\n",
            "| qf2_loss                | 1.5665944e-07 |\n",
            "| time_elapsed            | 180           |\n",
            "| total timesteps         | 35776         |\n",
            "| value_loss              | 0.0001215777  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0085603325  |\n",
            "| ent_coef_loss           | 0.6504173     |\n",
            "| entropy                 | 0.8215139     |\n",
            "| episodes                | 10610         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 35773         |\n",
            "| policy_loss             | -0.66207236   |\n",
            "| qf1_loss                | 5.533658e-07  |\n",
            "| qf2_loss                | 5.708047e-07  |\n",
            "| time_elapsed            | 180           |\n",
            "| total timesteps         | 35872         |\n",
            "| value_loss              | 0.00014674556 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008505687   |\n",
            "| ent_coef_loss           | 0.3494484     |\n",
            "| entropy                 | 0.9535481     |\n",
            "| episodes                | 10620         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 35879         |\n",
            "| policy_loss             | -0.5964422    |\n",
            "| qf1_loss                | 8.6899695e-07 |\n",
            "| qf2_loss                | 1.5546254e-07 |\n",
            "| time_elapsed            | 181           |\n",
            "| total timesteps         | 35978         |\n",
            "| value_loss              | 0.00015735975 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008487707    |\n",
            "| ent_coef_loss           | -0.7247616     |\n",
            "| entropy                 | 0.97225344     |\n",
            "| episodes                | 10630          |\n",
            "| fps                     | 198            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 35975          |\n",
            "| policy_loss             | -0.5647466     |\n",
            "| qf1_loss                | 3.2132475e-06  |\n",
            "| qf2_loss                | 2.635536e-06   |\n",
            "| time_elapsed            | 181            |\n",
            "| total timesteps         | 36074          |\n",
            "| value_loss              | 0.000114734605 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008489893   |\n",
            "| ent_coef_loss           | 0.21905378    |\n",
            "| entropy                 | 0.8329067     |\n",
            "| episodes                | 10640         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 36068         |\n",
            "| policy_loss             | -0.6236311    |\n",
            "| qf1_loss                | 4.9413325e-07 |\n",
            "| qf2_loss                | 2.6945162e-07 |\n",
            "| time_elapsed            | 182           |\n",
            "| total timesteps         | 36167         |\n",
            "| value_loss              | 0.00013897326 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008513479   |\n",
            "| ent_coef_loss           | -0.72102153   |\n",
            "| entropy                 | 0.9145917     |\n",
            "| episodes                | 10650         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 36149         |\n",
            "| policy_loss             | -0.6104144    |\n",
            "| qf1_loss                | 4.6818107e-07 |\n",
            "| qf2_loss                | 3.3910462e-07 |\n",
            "| time_elapsed            | 182           |\n",
            "| total timesteps         | 36248         |\n",
            "| value_loss              | 0.00016323008 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008563349   |\n",
            "| ent_coef_loss           | -0.08970606   |\n",
            "| entropy                 | 0.93881154    |\n",
            "| episodes                | 10660         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 36227         |\n",
            "| policy_loss             | -0.6187643    |\n",
            "| qf1_loss                | 6.84307e-07   |\n",
            "| qf2_loss                | 6.4620167e-07 |\n",
            "| time_elapsed            | 182           |\n",
            "| total timesteps         | 36326         |\n",
            "| value_loss              | 0.00013992941 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008555994   |\n",
            "| ent_coef_loss           | -0.44436795   |\n",
            "| entropy                 | 0.91862935    |\n",
            "| episodes                | 10670         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 36313         |\n",
            "| policy_loss             | -0.6402893    |\n",
            "| qf1_loss                | 8.91715e-07   |\n",
            "| qf2_loss                | 3.604357e-07  |\n",
            "| time_elapsed            | 183           |\n",
            "| total timesteps         | 36412         |\n",
            "| value_loss              | 0.00013868834 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008569117   |\n",
            "| ent_coef_loss           | 0.37023565    |\n",
            "| entropy                 | 0.82532644    |\n",
            "| episodes                | 10680         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 36380         |\n",
            "| policy_loss             | -0.67013955   |\n",
            "| qf1_loss                | 6.003853e-07  |\n",
            "| qf2_loss                | 2.989291e-07  |\n",
            "| time_elapsed            | 183           |\n",
            "| total timesteps         | 36479         |\n",
            "| value_loss              | 0.00012051441 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008599279    |\n",
            "| ent_coef_loss           | -0.38935474    |\n",
            "| entropy                 | 0.93220204     |\n",
            "| episodes                | 10690          |\n",
            "| fps                     | 198            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 36445          |\n",
            "| policy_loss             | -0.60619974    |\n",
            "| qf1_loss                | 4.6022353e-07  |\n",
            "| qf2_loss                | 1.4603986e-06  |\n",
            "| time_elapsed            | 184            |\n",
            "| total timesteps         | 36544          |\n",
            "| value_loss              | 0.000111245434 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008563618   |\n",
            "| ent_coef_loss           | -0.97474146   |\n",
            "| entropy                 | 0.98501825    |\n",
            "| episodes                | 10700         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 36532         |\n",
            "| policy_loss             | -0.5779325    |\n",
            "| qf1_loss                | 1.0753838e-06 |\n",
            "| qf2_loss                | 1.8655786e-07 |\n",
            "| time_elapsed            | 184           |\n",
            "| total timesteps         | 36631         |\n",
            "| value_loss              | 0.00010868875 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0085054645  |\n",
            "| ent_coef_loss           | 0.933359      |\n",
            "| entropy                 | 0.90173256    |\n",
            "| episodes                | 10710         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 36626         |\n",
            "| policy_loss             | -0.6358235    |\n",
            "| qf1_loss                | 3.251299e-07  |\n",
            "| qf2_loss                | 2.5978892e-07 |\n",
            "| time_elapsed            | 184           |\n",
            "| total timesteps         | 36725         |\n",
            "| value_loss              | 0.00011525338 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0085814     |\n",
            "| ent_coef_loss           | -0.13341355   |\n",
            "| entropy                 | 0.9305614     |\n",
            "| episodes                | 10720         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 36711         |\n",
            "| policy_loss             | -0.6186004    |\n",
            "| qf1_loss                | 4.3138658e-07 |\n",
            "| qf2_loss                | 1.0761194e-06 |\n",
            "| time_elapsed            | 185           |\n",
            "| total timesteps         | 36810         |\n",
            "| value_loss              | 0.00013097904 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0085779885  |\n",
            "| ent_coef_loss           | 0.7342835     |\n",
            "| entropy                 | 1.0654273     |\n",
            "| episodes                | 10730         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 36789         |\n",
            "| policy_loss             | -0.609415     |\n",
            "| qf1_loss                | 4.8255936e-07 |\n",
            "| qf2_loss                | 2.5848422e-07 |\n",
            "| time_elapsed            | 185           |\n",
            "| total timesteps         | 36888         |\n",
            "| value_loss              | 0.00010373123 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008525661   |\n",
            "| ent_coef_loss           | -0.5707283    |\n",
            "| entropy                 | 1.0042093     |\n",
            "| episodes                | 10740         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 36876         |\n",
            "| policy_loss             | -0.58300954   |\n",
            "| qf1_loss                | 1.1618104e-06 |\n",
            "| qf2_loss                | 1.5097919e-07 |\n",
            "| time_elapsed            | 186           |\n",
            "| total timesteps         | 36975         |\n",
            "| value_loss              | 0.00012246006 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008443356   |\n",
            "| ent_coef_loss           | 1.1158752     |\n",
            "| entropy                 | 0.87562704    |\n",
            "| episodes                | 10750         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 36946         |\n",
            "| policy_loss             | -0.65568197   |\n",
            "| qf1_loss                | 4.0481171e-07 |\n",
            "| qf2_loss                | 5.1733804e-07 |\n",
            "| time_elapsed            | 186           |\n",
            "| total timesteps         | 37045         |\n",
            "| value_loss              | 0.00013455309 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008397811   |\n",
            "| ent_coef_loss           | 0.8704394     |\n",
            "| entropy                 | 0.9473665     |\n",
            "| episodes                | 10760         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 37024         |\n",
            "| policy_loss             | -0.62743086   |\n",
            "| qf1_loss                | 9.789937e-07  |\n",
            "| qf2_loss                | 6.0132544e-07 |\n",
            "| time_elapsed            | 186           |\n",
            "| total timesteps         | 37123         |\n",
            "| value_loss              | 0.00016704501 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008397883   |\n",
            "| ent_coef_loss           | 0.4753862     |\n",
            "| entropy                 | 0.9612386     |\n",
            "| episodes                | 10770         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 37122         |\n",
            "| policy_loss             | -0.61074114   |\n",
            "| qf1_loss                | 6.4049914e-07 |\n",
            "| qf2_loss                | 1.2314908e-06 |\n",
            "| time_elapsed            | 187           |\n",
            "| total timesteps         | 37221         |\n",
            "| value_loss              | 0.00014989315 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008424856   |\n",
            "| ent_coef_loss           | -0.44294715   |\n",
            "| entropy                 | 0.916167      |\n",
            "| episodes                | 10780         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 37201         |\n",
            "| policy_loss             | -0.6001032    |\n",
            "| qf1_loss                | 5.119551e-07  |\n",
            "| qf2_loss                | 1.1515472e-06 |\n",
            "| time_elapsed            | 187           |\n",
            "| total timesteps         | 37300         |\n",
            "| value_loss              | 0.00015383986 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008413647   |\n",
            "| ent_coef_loss           | -0.5774239    |\n",
            "| entropy                 | 0.9828327     |\n",
            "| episodes                | 10790         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 37277         |\n",
            "| policy_loss             | -0.6278807    |\n",
            "| qf1_loss                | 7.5550105e-07 |\n",
            "| qf2_loss                | 4.4657713e-07 |\n",
            "| time_elapsed            | 188           |\n",
            "| total timesteps         | 37376         |\n",
            "| value_loss              | 0.00016074114 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008381525   |\n",
            "| ent_coef_loss           | -1.8965626    |\n",
            "| entropy                 | 1.0071081     |\n",
            "| episodes                | 10800         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 37352         |\n",
            "| policy_loss             | -0.6115688    |\n",
            "| qf1_loss                | 1.44479e-06   |\n",
            "| qf2_loss                | 1.8714482e-07 |\n",
            "| time_elapsed            | 188           |\n",
            "| total timesteps         | 37451         |\n",
            "| value_loss              | 0.00019675364 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008387938   |\n",
            "| ent_coef_loss           | -1.1875297    |\n",
            "| entropy                 | 1.0389378     |\n",
            "| episodes                | 10810         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 37426         |\n",
            "| policy_loss             | -0.5808628    |\n",
            "| qf1_loss                | 8.71912e-07   |\n",
            "| qf2_loss                | 4.7964877e-06 |\n",
            "| time_elapsed            | 188           |\n",
            "| total timesteps         | 37525         |\n",
            "| value_loss              | 0.00017709163 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008409973   |\n",
            "| ent_coef_loss           | 0.7170986     |\n",
            "| entropy                 | 0.9501757     |\n",
            "| episodes                | 10820         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 37534         |\n",
            "| policy_loss             | -0.6000241    |\n",
            "| qf1_loss                | 2.8952327e-06 |\n",
            "| qf2_loss                | 3.3228184e-07 |\n",
            "| time_elapsed            | 189           |\n",
            "| total timesteps         | 37633         |\n",
            "| value_loss              | 0.00014012204 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008462824    |\n",
            "| ent_coef_loss           | 0.036642283    |\n",
            "| entropy                 | 0.8715939      |\n",
            "| episodes                | 10830          |\n",
            "| fps                     | 198            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 37631          |\n",
            "| policy_loss             | -0.64642304    |\n",
            "| qf1_loss                | 5.4037616e-07  |\n",
            "| qf2_loss                | 1.977202e-07   |\n",
            "| time_elapsed            | 189            |\n",
            "| total timesteps         | 37730          |\n",
            "| value_loss              | 0.000118471224 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008484154   |\n",
            "| ent_coef_loss           | -0.38205326   |\n",
            "| entropy                 | 0.95613444    |\n",
            "| episodes                | 10840         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 37721         |\n",
            "| policy_loss             | -0.60822684   |\n",
            "| qf1_loss                | 1.1059169e-06 |\n",
            "| qf2_loss                | 3.573423e-07  |\n",
            "| time_elapsed            | 190           |\n",
            "| total timesteps         | 37820         |\n",
            "| value_loss              | 0.00018706163 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.0085218325   |\n",
            "| ent_coef_loss           | 0.21677774     |\n",
            "| entropy                 | 0.95953393     |\n",
            "| episodes                | 10850          |\n",
            "| fps                     | 198            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 37789          |\n",
            "| policy_loss             | -0.61494195    |\n",
            "| qf1_loss                | 4.3541564e-07  |\n",
            "| qf2_loss                | 1.5599736e-07  |\n",
            "| time_elapsed            | 190            |\n",
            "| total timesteps         | 37888          |\n",
            "| value_loss              | 0.000101759564 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008509327   |\n",
            "| ent_coef_loss           | -0.7941165    |\n",
            "| entropy                 | 1.0043681     |\n",
            "| episodes                | 10860         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 37876         |\n",
            "| policy_loss             | -0.61623037   |\n",
            "| qf1_loss                | 6.3381367e-07 |\n",
            "| qf2_loss                | 4.7646427e-07 |\n",
            "| time_elapsed            | 190           |\n",
            "| total timesteps         | 37975         |\n",
            "| value_loss              | 0.00012715107 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008509497   |\n",
            "| ent_coef_loss           | -1.0575206    |\n",
            "| entropy                 | 1.0068552     |\n",
            "| episodes                | 10870         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 37981         |\n",
            "| policy_loss             | -0.60762185   |\n",
            "| qf1_loss                | 7.337918e-07  |\n",
            "| qf2_loss                | 1.7823707e-07 |\n",
            "| time_elapsed            | 191           |\n",
            "| total timesteps         | 38080         |\n",
            "| value_loss              | 0.00015100374 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008546754   |\n",
            "| ent_coef_loss           | 0.01396811    |\n",
            "| entropy                 | 0.9861208     |\n",
            "| episodes                | 10880         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 38073         |\n",
            "| policy_loss             | -0.6372613    |\n",
            "| qf1_loss                | 5.6972044e-07 |\n",
            "| qf2_loss                | 2.3151894e-07 |\n",
            "| time_elapsed            | 191           |\n",
            "| total timesteps         | 38172         |\n",
            "| value_loss              | 0.00017708569 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008505043   |\n",
            "| ent_coef_loss           | 0.27127665    |\n",
            "| entropy                 | 1.0350629     |\n",
            "| episodes                | 10890         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 38173         |\n",
            "| policy_loss             | -0.61393225   |\n",
            "| qf1_loss                | 4.2203058e-07 |\n",
            "| qf2_loss                | 4.812595e-07  |\n",
            "| time_elapsed            | 192           |\n",
            "| total timesteps         | 38272         |\n",
            "| value_loss              | 0.00014161128 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008484522   |\n",
            "| ent_coef_loss           | 1.1908879     |\n",
            "| entropy                 | 0.846569      |\n",
            "| episodes                | 10900         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 38247         |\n",
            "| policy_loss             | -0.6407726    |\n",
            "| qf1_loss                | 1.262307e-06  |\n",
            "| qf2_loss                | 2.9928827e-07 |\n",
            "| time_elapsed            | 192           |\n",
            "| total timesteps         | 38346         |\n",
            "| value_loss              | 0.00013488403 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008504223   |\n",
            "| ent_coef_loss           | -0.8495698    |\n",
            "| entropy                 | 1.0411043     |\n",
            "| episodes                | 10910         |\n",
            "| fps                     | 198           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 38347         |\n",
            "| policy_loss             | -0.5815319    |\n",
            "| qf1_loss                | 7.181317e-07  |\n",
            "| qf2_loss                | 7.176471e-07  |\n",
            "| time_elapsed            | 193           |\n",
            "| total timesteps         | 38446         |\n",
            "| value_loss              | 0.00013826432 |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| current_lr              | 0.0003       |\n",
            "| ent_coef                | 0.008565673  |\n",
            "| ent_coef_loss           | 0.4462931    |\n",
            "| entropy                 | 1.0022655    |\n",
            "| episodes                | 10920        |\n",
            "| fps                     | 198          |\n",
            "| mean 100 episode reward | 0.9          |\n",
            "| n_updates               | 38475        |\n",
            "| policy_loss             | -0.63757896  |\n",
            "| qf1_loss                | 9.493548e-07 |\n",
            "| qf2_loss                | 4.990299e-07 |\n",
            "| time_elapsed            | 193          |\n",
            "| total timesteps         | 38574        |\n",
            "| value_loss              | 9.508854e-05 |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008526137   |\n",
            "| ent_coef_loss           | -0.47193766   |\n",
            "| entropy                 | 1.0282574     |\n",
            "| episodes                | 10930         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 38566         |\n",
            "| policy_loss             | -0.6047838    |\n",
            "| qf1_loss                | 6.561993e-07  |\n",
            "| qf2_loss                | 1.5921485e-06 |\n",
            "| time_elapsed            | 194           |\n",
            "| total timesteps         | 38665         |\n",
            "| value_loss              | 0.00018803959 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00852384    |\n",
            "| ent_coef_loss           | 0.011751652   |\n",
            "| entropy                 | 0.9177325     |\n",
            "| episodes                | 10940         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 38658         |\n",
            "| policy_loss             | -0.6446154    |\n",
            "| qf1_loss                | 8.6930055e-07 |\n",
            "| qf2_loss                | 1.2173896e-06 |\n",
            "| time_elapsed            | 194           |\n",
            "| total timesteps         | 38757         |\n",
            "| value_loss              | 0.0001478455  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008536901   |\n",
            "| ent_coef_loss           | -0.31718445   |\n",
            "| entropy                 | 1.008109      |\n",
            "| episodes                | 10950         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 38721         |\n",
            "| policy_loss             | -0.6117826    |\n",
            "| qf1_loss                | 7.896006e-07  |\n",
            "| qf2_loss                | 4.8589817e-07 |\n",
            "| time_elapsed            | 195           |\n",
            "| total timesteps         | 38820         |\n",
            "| value_loss              | 0.00013747298 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0085664205  |\n",
            "| ent_coef_loss           | -0.28580528   |\n",
            "| entropy                 | 0.96501994    |\n",
            "| episodes                | 10960         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 38824         |\n",
            "| policy_loss             | -0.61889976   |\n",
            "| qf1_loss                | 8.6491093e-07 |\n",
            "| qf2_loss                | 4.1499592e-07 |\n",
            "| time_elapsed            | 195           |\n",
            "| total timesteps         | 38923         |\n",
            "| value_loss              | 0.00021577367 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008529586   |\n",
            "| ent_coef_loss           | -1.3837721    |\n",
            "| entropy                 | 1.0776746     |\n",
            "| episodes                | 10970         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 38894         |\n",
            "| policy_loss             | -0.58275175   |\n",
            "| qf1_loss                | 4.6282855e-07 |\n",
            "| qf2_loss                | 3.0968118e-07 |\n",
            "| time_elapsed            | 195           |\n",
            "| total timesteps         | 38993         |\n",
            "| value_loss              | 0.00012270137 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008468383    |\n",
            "| ent_coef_loss           | 0.15221983     |\n",
            "| entropy                 | 0.96673936     |\n",
            "| episodes                | 10980          |\n",
            "| fps                     | 199            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 38968          |\n",
            "| policy_loss             | -0.6119011     |\n",
            "| qf1_loss                | 1.0286842e-06  |\n",
            "| qf2_loss                | 4.8183233e-07  |\n",
            "| time_elapsed            | 196            |\n",
            "| total timesteps         | 39067          |\n",
            "| value_loss              | 0.000106875086 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008466182   |\n",
            "| ent_coef_loss           | -0.9007313    |\n",
            "| entropy                 | 1.0084095     |\n",
            "| episodes                | 10990         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 39045         |\n",
            "| policy_loss             | -0.62747735   |\n",
            "| qf1_loss                | 2.4896747e-07 |\n",
            "| qf2_loss                | 6.3404974e-07 |\n",
            "| time_elapsed            | 196           |\n",
            "| total timesteps         | 39144         |\n",
            "| value_loss              | 0.00017458116 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008494274   |\n",
            "| ent_coef_loss           | -0.23621029   |\n",
            "| entropy                 | 0.9961184     |\n",
            "| episodes                | 11000         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 39134         |\n",
            "| policy_loss             | -0.6240977    |\n",
            "| qf1_loss                | 8.7671765e-07 |\n",
            "| qf2_loss                | 1.918378e-06  |\n",
            "| time_elapsed            | 197           |\n",
            "| total timesteps         | 39233         |\n",
            "| value_loss              | 0.00013498301 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008487031   |\n",
            "| ent_coef_loss           | -0.9987195    |\n",
            "| entropy                 | 1.0128694     |\n",
            "| episodes                | 11010         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 39242         |\n",
            "| policy_loss             | -0.5955044    |\n",
            "| qf1_loss                | 5.3247413e-07 |\n",
            "| qf2_loss                | 2.846732e-07  |\n",
            "| time_elapsed            | 197           |\n",
            "| total timesteps         | 39341         |\n",
            "| value_loss              | 0.00012385681 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008481884   |\n",
            "| ent_coef_loss           | 0.48127472    |\n",
            "| entropy                 | 1.0111517     |\n",
            "| episodes                | 11020         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 39346         |\n",
            "| policy_loss             | -0.6023929    |\n",
            "| qf1_loss                | 2.9363315e-07 |\n",
            "| qf2_loss                | 4.2494375e-07 |\n",
            "| time_elapsed            | 198           |\n",
            "| total timesteps         | 39445         |\n",
            "| value_loss              | 0.00013092182 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008478363   |\n",
            "| ent_coef_loss           | 0.6145276     |\n",
            "| entropy                 | 0.95328474    |\n",
            "| episodes                | 11030         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 39451         |\n",
            "| policy_loss             | -0.6120453    |\n",
            "| qf1_loss                | 1.7204212e-06 |\n",
            "| qf2_loss                | 4.8341224e-07 |\n",
            "| time_elapsed            | 198           |\n",
            "| total timesteps         | 39550         |\n",
            "| value_loss              | 0.00014739152 |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| current_lr              | 0.0003       |\n",
            "| ent_coef                | 0.008427802  |\n",
            "| ent_coef_loss           | -2.1632981   |\n",
            "| entropy                 | 0.9953677    |\n",
            "| episodes                | 11040        |\n",
            "| fps                     | 199          |\n",
            "| mean 100 episode reward | 0.9          |\n",
            "| n_updates               | 39553        |\n",
            "| policy_loss             | -0.60506415  |\n",
            "| qf1_loss                | 7.028667e-07 |\n",
            "| qf2_loss                | 2.234832e-07 |\n",
            "| time_elapsed            | 199          |\n",
            "| total timesteps         | 39652        |\n",
            "| value_loss              | 0.0001657572 |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008404321   |\n",
            "| ent_coef_loss           | -2.1001291    |\n",
            "| entropy                 | 1.0559032     |\n",
            "| episodes                | 11050         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 39652         |\n",
            "| policy_loss             | -0.61604786   |\n",
            "| qf1_loss                | 3.9590515e-07 |\n",
            "| qf2_loss                | 1.8174339e-07 |\n",
            "| time_elapsed            | 199           |\n",
            "| total timesteps         | 39751         |\n",
            "| value_loss              | 0.00017394955 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008316248   |\n",
            "| ent_coef_loss           | 0.8309895     |\n",
            "| entropy                 | 0.895421      |\n",
            "| episodes                | 11060         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 39725         |\n",
            "| policy_loss             | -0.6738076    |\n",
            "| qf1_loss                | 4.3533214e-07 |\n",
            "| qf2_loss                | 1.1810137e-06 |\n",
            "| time_elapsed            | 199           |\n",
            "| total timesteps         | 39824         |\n",
            "| value_loss              | 0.00012322998 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008322761   |\n",
            "| ent_coef_loss           | 0.39652947    |\n",
            "| entropy                 | 0.98305       |\n",
            "| episodes                | 11070         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 39817         |\n",
            "| policy_loss             | -0.6291269    |\n",
            "| qf1_loss                | 2.5689508e-07 |\n",
            "| qf2_loss                | 5.026415e-07  |\n",
            "| time_elapsed            | 200           |\n",
            "| total timesteps         | 39916         |\n",
            "| value_loss              | 0.00015951674 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008344602   |\n",
            "| ent_coef_loss           | -2.1396608    |\n",
            "| entropy                 | 1.0590975     |\n",
            "| episodes                | 11080         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 39921         |\n",
            "| policy_loss             | -0.60780597   |\n",
            "| qf1_loss                | 8.2134034e-07 |\n",
            "| qf2_loss                | 4.3754565e-07 |\n",
            "| time_elapsed            | 200           |\n",
            "| total timesteps         | 40020         |\n",
            "| value_loss              | 0.00019251285 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008341045   |\n",
            "| ent_coef_loss           | -2.0710084    |\n",
            "| entropy                 | 1.139826      |\n",
            "| episodes                | 11090         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 39984         |\n",
            "| policy_loss             | -0.6103376    |\n",
            "| qf1_loss                | 2.448301e-07  |\n",
            "| qf2_loss                | 2.4910267e-07 |\n",
            "| time_elapsed            | 201           |\n",
            "| total timesteps         | 40083         |\n",
            "| value_loss              | 0.00019394606 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008370913   |\n",
            "| ent_coef_loss           | 0.43245524    |\n",
            "| entropy                 | 1.0385439     |\n",
            "| episodes                | 11100         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 40083         |\n",
            "| policy_loss             | -0.6062198    |\n",
            "| qf1_loss                | 3.1854705e-07 |\n",
            "| qf2_loss                | 2.432399e-06  |\n",
            "| time_elapsed            | 201           |\n",
            "| total timesteps         | 40182         |\n",
            "| value_loss              | 9.417515e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008350688   |\n",
            "| ent_coef_loss           | -0.7562745    |\n",
            "| entropy                 | 0.9403997     |\n",
            "| episodes                | 11110         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 40166         |\n",
            "| policy_loss             | -0.6219175    |\n",
            "| qf1_loss                | 4.8012237e-07 |\n",
            "| qf2_loss                | 6.421426e-07  |\n",
            "| time_elapsed            | 202           |\n",
            "| total timesteps         | 40265         |\n",
            "| value_loss              | 0.00015062507 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008330138   |\n",
            "| ent_coef_loss           | -0.37225345   |\n",
            "| entropy                 | 1.1650475     |\n",
            "| episodes                | 11120         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 40245         |\n",
            "| policy_loss             | -0.5921958    |\n",
            "| qf1_loss                | 1.0209646e-06 |\n",
            "| qf2_loss                | 9.3816794e-07 |\n",
            "| time_elapsed            | 202           |\n",
            "| total timesteps         | 40344         |\n",
            "| value_loss              | 0.00013709132 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008305294    |\n",
            "| ent_coef_loss           | 0.73269695     |\n",
            "| entropy                 | 1.0343834      |\n",
            "| episodes                | 11130          |\n",
            "| fps                     | 199            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 40353          |\n",
            "| policy_loss             | -0.61069965    |\n",
            "| qf1_loss                | 5.512567e-07   |\n",
            "| qf2_loss                | 4.2660605e-07  |\n",
            "| time_elapsed            | 202            |\n",
            "| total timesteps         | 40452          |\n",
            "| value_loss              | 0.000118302705 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008303441   |\n",
            "| ent_coef_loss           | -0.37530637   |\n",
            "| entropy                 | 0.9989475     |\n",
            "| episodes                | 11140         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 40423         |\n",
            "| policy_loss             | -0.5892031    |\n",
            "| qf1_loss                | 4.7254576e-07 |\n",
            "| qf2_loss                | 6.412789e-07  |\n",
            "| time_elapsed            | 203           |\n",
            "| total timesteps         | 40522         |\n",
            "| value_loss              | 0.0001200641  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008298719   |\n",
            "| ent_coef_loss           | -0.1587629    |\n",
            "| entropy                 | 1.1291666     |\n",
            "| episodes                | 11150         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 40482         |\n",
            "| policy_loss             | -0.59709966   |\n",
            "| qf1_loss                | 5.007924e-07  |\n",
            "| qf2_loss                | 4.2046665e-07 |\n",
            "| time_elapsed            | 203           |\n",
            "| total timesteps         | 40581         |\n",
            "| value_loss              | 0.00011741111 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008210731    |\n",
            "| ent_coef_loss           | -0.96260047    |\n",
            "| entropy                 | 1.0432107      |\n",
            "| episodes                | 11160          |\n",
            "| fps                     | 199            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 40546          |\n",
            "| policy_loss             | -0.5880385     |\n",
            "| qf1_loss                | 3.2628836e-07  |\n",
            "| qf2_loss                | 2.568826e-07   |\n",
            "| time_elapsed            | 203            |\n",
            "| total timesteps         | 40645          |\n",
            "| value_loss              | 0.000115210125 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008226642   |\n",
            "| ent_coef_loss           | -0.05359572   |\n",
            "| entropy                 | 0.9895795     |\n",
            "| episodes                | 11170         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 40628         |\n",
            "| policy_loss             | -0.6287923    |\n",
            "| qf1_loss                | 1.4291187e-06 |\n",
            "| qf2_loss                | 3.0459643e-07 |\n",
            "| time_elapsed            | 204           |\n",
            "| total timesteps         | 40727         |\n",
            "| value_loss              | 0.0001560231  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008247239   |\n",
            "| ent_coef_loss           | -0.12442589   |\n",
            "| entropy                 | 1.0279853     |\n",
            "| episodes                | 11180         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 40691         |\n",
            "| policy_loss             | -0.58958006   |\n",
            "| qf1_loss                | 8.22027e-07   |\n",
            "| qf2_loss                | 5.3263176e-07 |\n",
            "| time_elapsed            | 204           |\n",
            "| total timesteps         | 40790         |\n",
            "| value_loss              | 0.00011831845 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008232316   |\n",
            "| ent_coef_loss           | -0.12031764   |\n",
            "| entropy                 | 0.93253493    |\n",
            "| episodes                | 11190         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 40774         |\n",
            "| policy_loss             | -0.65007204   |\n",
            "| qf1_loss                | 5.566618e-07  |\n",
            "| qf2_loss                | 4.10187e-07   |\n",
            "| time_elapsed            | 204           |\n",
            "| total timesteps         | 40873         |\n",
            "| value_loss              | 0.00014919257 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008274793   |\n",
            "| ent_coef_loss           | 0.10384411    |\n",
            "| entropy                 | 1.048264      |\n",
            "| episodes                | 11200         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 40860         |\n",
            "| policy_loss             | -0.59182405   |\n",
            "| qf1_loss                | 1.9008796e-06 |\n",
            "| qf2_loss                | 5.3485223e-07 |\n",
            "| time_elapsed            | 205           |\n",
            "| total timesteps         | 40959         |\n",
            "| value_loss              | 0.00014426839 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.0082960045   |\n",
            "| ent_coef_loss           | 0.6371235      |\n",
            "| entropy                 | 1.026506       |\n",
            "| episodes                | 11210          |\n",
            "| fps                     | 199            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 40971          |\n",
            "| policy_loss             | -0.6199003     |\n",
            "| qf1_loss                | 5.214823e-07   |\n",
            "| qf2_loss                | 4.6272407e-07  |\n",
            "| time_elapsed            | 205            |\n",
            "| total timesteps         | 41070          |\n",
            "| value_loss              | 0.000121157645 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008309037   |\n",
            "| ent_coef_loss           | 0.69964635    |\n",
            "| entropy                 | 0.94917357    |\n",
            "| episodes                | 11220         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 41068         |\n",
            "| policy_loss             | -0.6259655    |\n",
            "| qf1_loss                | 2.2278941e-07 |\n",
            "| qf2_loss                | 3.5153528e-07 |\n",
            "| time_elapsed            | 206           |\n",
            "| total timesteps         | 41167         |\n",
            "| value_loss              | 0.00014249027 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008293022   |\n",
            "| ent_coef_loss           | 1.8876336     |\n",
            "| entropy                 | 0.9569421     |\n",
            "| episodes                | 11230         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 41151         |\n",
            "| policy_loss             | -0.6434086    |\n",
            "| qf1_loss                | 1.0486374e-06 |\n",
            "| qf2_loss                | 4.7528562e-07 |\n",
            "| time_elapsed            | 206           |\n",
            "| total timesteps         | 41250         |\n",
            "| value_loss              | 9.4887386e-05 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008318088   |\n",
            "| ent_coef_loss           | 2.1432085     |\n",
            "| entropy                 | 0.8770795     |\n",
            "| episodes                | 11240         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 41256         |\n",
            "| policy_loss             | -0.6642953    |\n",
            "| qf1_loss                | 7.4264085e-07 |\n",
            "| qf2_loss                | 3.2193307e-07 |\n",
            "| time_elapsed            | 207           |\n",
            "| total timesteps         | 41355         |\n",
            "| value_loss              | 0.00012294651 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008304795   |\n",
            "| ent_coef_loss           | 0.058555603   |\n",
            "| entropy                 | 1.0885506     |\n",
            "| episodes                | 11250         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 41362         |\n",
            "| policy_loss             | -0.5721737    |\n",
            "| qf1_loss                | 7.741334e-07  |\n",
            "| qf2_loss                | 2.6709756e-07 |\n",
            "| time_elapsed            | 207           |\n",
            "| total timesteps         | 41461         |\n",
            "| value_loss              | 0.00012267171 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008299031    |\n",
            "| ent_coef_loss           | 0.4300449      |\n",
            "| entropy                 | 1.035419       |\n",
            "| episodes                | 11260          |\n",
            "| fps                     | 199            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 41456          |\n",
            "| policy_loss             | -0.6305641     |\n",
            "| qf1_loss                | 5.942702e-07   |\n",
            "| qf2_loss                | 4.31804e-07    |\n",
            "| time_elapsed            | 208            |\n",
            "| total timesteps         | 41555          |\n",
            "| value_loss              | 0.000120677505 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0083299875  |\n",
            "| ent_coef_loss           | 1.1646254     |\n",
            "| entropy                 | 1.0848558     |\n",
            "| episodes                | 11270         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 41564         |\n",
            "| policy_loss             | -0.6363815    |\n",
            "| qf1_loss                | 1.0090516e-06 |\n",
            "| qf2_loss                | 3.205003e-07  |\n",
            "| time_elapsed            | 208           |\n",
            "| total timesteps         | 41663         |\n",
            "| value_loss              | 0.0001569618  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008337546   |\n",
            "| ent_coef_loss           | 0.10817248    |\n",
            "| entropy                 | 1.0136466     |\n",
            "| episodes                | 11280         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 41637         |\n",
            "| policy_loss             | -0.604883     |\n",
            "| qf1_loss                | 7.3013587e-07 |\n",
            "| qf2_loss                | 1.6818497e-06 |\n",
            "| time_elapsed            | 209           |\n",
            "| total timesteps         | 41736         |\n",
            "| value_loss              | 0.00013362846 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008336115   |\n",
            "| ent_coef_loss           | 0.4918969     |\n",
            "| entropy                 | 1.0305164     |\n",
            "| episodes                | 11290         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 41718         |\n",
            "| policy_loss             | -0.63012624   |\n",
            "| qf1_loss                | 5.3265785e-07 |\n",
            "| qf2_loss                | 2.251598e-06  |\n",
            "| time_elapsed            | 209           |\n",
            "| total timesteps         | 41817         |\n",
            "| value_loss              | 0.00010092942 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0082747815  |\n",
            "| ent_coef_loss           | -1.3790576    |\n",
            "| entropy                 | 1.0596317     |\n",
            "| episodes                | 11300         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 41804         |\n",
            "| policy_loss             | -0.61189497   |\n",
            "| qf1_loss                | 1.2312653e-06 |\n",
            "| qf2_loss                | 3.237824e-07  |\n",
            "| time_elapsed            | 210           |\n",
            "| total timesteps         | 41903         |\n",
            "| value_loss              | 0.00016088644 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008254076   |\n",
            "| ent_coef_loss           | -1.17938      |\n",
            "| entropy                 | 1.2223816     |\n",
            "| episodes                | 11310         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 41908         |\n",
            "| policy_loss             | -0.57199615   |\n",
            "| qf1_loss                | 9.0150957e-07 |\n",
            "| qf2_loss                | 7.464701e-07  |\n",
            "| time_elapsed            | 210           |\n",
            "| total timesteps         | 42007         |\n",
            "| value_loss              | 0.00012525376 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008305794    |\n",
            "| ent_coef_loss           | 2.0678172      |\n",
            "| entropy                 | 1.0471413      |\n",
            "| episodes                | 11320          |\n",
            "| fps                     | 199            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 41988          |\n",
            "| policy_loss             | -0.604336      |\n",
            "| qf1_loss                | 4.733367e-07   |\n",
            "| qf2_loss                | 4.802915e-06   |\n",
            "| time_elapsed            | 210            |\n",
            "| total timesteps         | 42087          |\n",
            "| value_loss              | 0.000104371305 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008341392   |\n",
            "| ent_coef_loss           | 0.1601528     |\n",
            "| entropy                 | 1.0056086     |\n",
            "| episodes                | 11330         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 42103         |\n",
            "| policy_loss             | -0.62295604   |\n",
            "| qf1_loss                | 6.331647e-07  |\n",
            "| qf2_loss                | 2.3784345e-07 |\n",
            "| time_elapsed            | 211           |\n",
            "| total timesteps         | 42202         |\n",
            "| value_loss              | 0.00014478722 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008341884   |\n",
            "| ent_coef_loss           | -1.7721748    |\n",
            "| entropy                 | 1.1130784     |\n",
            "| episodes                | 11340         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 42194         |\n",
            "| policy_loss             | -0.5843258    |\n",
            "| qf1_loss                | 4.2809563e-07 |\n",
            "| qf2_loss                | 3.1181122e-07 |\n",
            "| time_elapsed            | 211           |\n",
            "| total timesteps         | 42293         |\n",
            "| value_loss              | 0.00013033484 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00834689    |\n",
            "| ent_coef_loss           | 1.0926207     |\n",
            "| entropy                 | 1.0697021     |\n",
            "| episodes                | 11350         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 42258         |\n",
            "| policy_loss             | -0.61892724   |\n",
            "| qf1_loss                | 9.353291e-07  |\n",
            "| qf2_loss                | 2.1719234e-07 |\n",
            "| time_elapsed            | 212           |\n",
            "| total timesteps         | 42357         |\n",
            "| value_loss              | 0.00016870984 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008351915   |\n",
            "| ent_coef_loss           | 0.6313027     |\n",
            "| entropy                 | 0.96258295    |\n",
            "| episodes                | 11360         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 42356         |\n",
            "| policy_loss             | -0.6389576    |\n",
            "| qf1_loss                | 1.5605456e-06 |\n",
            "| qf2_loss                | 6.047419e-07  |\n",
            "| time_elapsed            | 212           |\n",
            "| total timesteps         | 42455         |\n",
            "| value_loss              | 0.00012633175 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0083247665  |\n",
            "| ent_coef_loss           | 1.5955639     |\n",
            "| entropy                 | 1.0476147     |\n",
            "| episodes                | 11370         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 42465         |\n",
            "| policy_loss             | -0.593308     |\n",
            "| qf1_loss                | 4.7965943e-07 |\n",
            "| qf2_loss                | 6.6821366e-07 |\n",
            "| time_elapsed            | 213           |\n",
            "| total timesteps         | 42564         |\n",
            "| value_loss              | 0.00011309202 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008316855   |\n",
            "| ent_coef_loss           | -0.09645736   |\n",
            "| entropy                 | 1.0364668     |\n",
            "| episodes                | 11380         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 42546         |\n",
            "| policy_loss             | -0.6495891    |\n",
            "| qf1_loss                | 1.9060504e-06 |\n",
            "| qf2_loss                | 2.8454843e-07 |\n",
            "| time_elapsed            | 213           |\n",
            "| total timesteps         | 42645         |\n",
            "| value_loss              | 0.00015397667 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00825486    |\n",
            "| ent_coef_loss           | -0.6265473    |\n",
            "| entropy                 | 0.99405533    |\n",
            "| episodes                | 11390         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 42659         |\n",
            "| policy_loss             | -0.6028761    |\n",
            "| qf1_loss                | 5.750453e-07  |\n",
            "| qf2_loss                | 2.0359265e-07 |\n",
            "| time_elapsed            | 214           |\n",
            "| total timesteps         | 42758         |\n",
            "| value_loss              | 0.00018692567 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008297852   |\n",
            "| ent_coef_loss           | 1.3265998     |\n",
            "| entropy                 | 1.0316436     |\n",
            "| episodes                | 11400         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 42750         |\n",
            "| policy_loss             | -0.63363063   |\n",
            "| qf1_loss                | 3.9049246e-07 |\n",
            "| qf2_loss                | 4.727837e-07  |\n",
            "| time_elapsed            | 214           |\n",
            "| total timesteps         | 42849         |\n",
            "| value_loss              | 8.860283e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008318774   |\n",
            "| ent_coef_loss           | 0.47362643    |\n",
            "| entropy                 | 1.0424654     |\n",
            "| episodes                | 11410         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 42873         |\n",
            "| policy_loss             | -0.6297744    |\n",
            "| qf1_loss                | 5.4818804e-07 |\n",
            "| qf2_loss                | 3.0406486e-07 |\n",
            "| time_elapsed            | 215           |\n",
            "| total timesteps         | 42972         |\n",
            "| value_loss              | 0.0001554646  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008369344   |\n",
            "| ent_coef_loss           | 1.8460534     |\n",
            "| entropy                 | 0.95637494    |\n",
            "| episodes                | 11420         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 42970         |\n",
            "| policy_loss             | -0.6146001    |\n",
            "| qf1_loss                | 6.035085e-07  |\n",
            "| qf2_loss                | 5.3544863e-07 |\n",
            "| time_elapsed            | 215           |\n",
            "| total timesteps         | 43069         |\n",
            "| value_loss              | 8.641125e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008468641   |\n",
            "| ent_coef_loss           | -0.8921664    |\n",
            "| entropy                 | 1.1176863     |\n",
            "| episodes                | 11430         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 43068         |\n",
            "| policy_loss             | -0.5886848    |\n",
            "| qf1_loss                | 2.5184448e-07 |\n",
            "| qf2_loss                | 2.1855253e-06 |\n",
            "| time_elapsed            | 216           |\n",
            "| total timesteps         | 43167         |\n",
            "| value_loss              | 0.00014935649 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008448181   |\n",
            "| ent_coef_loss           | 0.50272334    |\n",
            "| entropy                 | 1.1120751     |\n",
            "| episodes                | 11440         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 43131         |\n",
            "| policy_loss             | -0.612303     |\n",
            "| qf1_loss                | 2.1740457e-06 |\n",
            "| qf2_loss                | 7.2237475e-07 |\n",
            "| time_elapsed            | 216           |\n",
            "| total timesteps         | 43230         |\n",
            "| value_loss              | 0.00015732745 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00837435    |\n",
            "| ent_coef_loss           | 0.90031266    |\n",
            "| entropy                 | 0.98943853    |\n",
            "| episodes                | 11450         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 43225         |\n",
            "| policy_loss             | -0.61973894   |\n",
            "| qf1_loss                | 4.7470104e-07 |\n",
            "| qf2_loss                | 2.885671e-07  |\n",
            "| time_elapsed            | 216           |\n",
            "| total timesteps         | 43324         |\n",
            "| value_loss              | 9.1866474e-05 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008371651   |\n",
            "| ent_coef_loss           | 0.9154017     |\n",
            "| entropy                 | 0.9903791     |\n",
            "| episodes                | 11460         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 43330         |\n",
            "| policy_loss             | -0.6257012    |\n",
            "| qf1_loss                | 8.2421997e-07 |\n",
            "| qf2_loss                | 9.079104e-07  |\n",
            "| time_elapsed            | 217           |\n",
            "| total timesteps         | 43429         |\n",
            "| value_loss              | 0.00011792415 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008329344   |\n",
            "| ent_coef_loss           | 0.9181709     |\n",
            "| entropy                 | 0.9921458     |\n",
            "| episodes                | 11470         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 43411         |\n",
            "| policy_loss             | -0.66671515   |\n",
            "| qf1_loss                | 4.834517e-07  |\n",
            "| qf2_loss                | 6.019685e-07  |\n",
            "| time_elapsed            | 217           |\n",
            "| total timesteps         | 43510         |\n",
            "| value_loss              | 0.00011318053 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008312371   |\n",
            "| ent_coef_loss           | 0.1305896     |\n",
            "| entropy                 | 0.9855197     |\n",
            "| episodes                | 11480         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 43472         |\n",
            "| policy_loss             | -0.6345263    |\n",
            "| qf1_loss                | 3.6930288e-07 |\n",
            "| qf2_loss                | 2.183497e-07  |\n",
            "| time_elapsed            | 218           |\n",
            "| total timesteps         | 43571         |\n",
            "| value_loss              | 0.00011461616 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008337471   |\n",
            "| ent_coef_loss           | 0.22293985    |\n",
            "| entropy                 | 1.0947089     |\n",
            "| episodes                | 11490         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 43568         |\n",
            "| policy_loss             | -0.5918975    |\n",
            "| qf1_loss                | 4.3895966e-07 |\n",
            "| qf2_loss                | 7.17067e-07   |\n",
            "| time_elapsed            | 218           |\n",
            "| total timesteps         | 43667         |\n",
            "| value_loss              | 0.00010712402 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00825595    |\n",
            "| ent_coef_loss           | -0.9392046    |\n",
            "| entropy                 | 1.0422878     |\n",
            "| episodes                | 11500         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 43659         |\n",
            "| policy_loss             | -0.6291       |\n",
            "| qf1_loss                | 2.3739145e-07 |\n",
            "| qf2_loss                | 9.1290406e-07 |\n",
            "| time_elapsed            | 218           |\n",
            "| total timesteps         | 43758         |\n",
            "| value_loss              | 0.00015497225 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008264158    |\n",
            "| ent_coef_loss           | -0.25499043    |\n",
            "| entropy                 | 1.057835       |\n",
            "| episodes                | 11510          |\n",
            "| fps                     | 199            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 43754          |\n",
            "| policy_loss             | -0.56721956    |\n",
            "| qf1_loss                | 6.8361214e-07  |\n",
            "| qf2_loss                | 2.982372e-07   |\n",
            "| time_elapsed            | 219            |\n",
            "| total timesteps         | 43853          |\n",
            "| value_loss              | 0.000110110515 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008272481   |\n",
            "| ent_coef_loss           | -0.00519827   |\n",
            "| entropy                 | 1.0413916     |\n",
            "| episodes                | 11520         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 43861         |\n",
            "| policy_loss             | -0.59962445   |\n",
            "| qf1_loss                | 5.5438875e-07 |\n",
            "| qf2_loss                | 6.2789763e-07 |\n",
            "| time_elapsed            | 219           |\n",
            "| total timesteps         | 43960         |\n",
            "| value_loss              | 0.00011319707 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008284398   |\n",
            "| ent_coef_loss           | -0.77693516   |\n",
            "| entropy                 | 1.0208311     |\n",
            "| episodes                | 11530         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 43926         |\n",
            "| policy_loss             | -0.6387228    |\n",
            "| qf1_loss                | 4.0168152e-07 |\n",
            "| qf2_loss                | 4.0699265e-07 |\n",
            "| time_elapsed            | 220           |\n",
            "| total timesteps         | 44025         |\n",
            "| value_loss              | 0.0001418474  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008274485   |\n",
            "| ent_coef_loss           | 0.13826227    |\n",
            "| entropy                 | 1.0405058     |\n",
            "| episodes                | 11540         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 44028         |\n",
            "| policy_loss             | -0.6427219    |\n",
            "| qf1_loss                | 8.0056896e-07 |\n",
            "| qf2_loss                | 2.6899187e-07 |\n",
            "| time_elapsed            | 220           |\n",
            "| total timesteps         | 44127         |\n",
            "| value_loss              | 0.00013749377 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008200996   |\n",
            "| ent_coef_loss           | 1.3447988     |\n",
            "| entropy                 | 0.908834      |\n",
            "| episodes                | 11550         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 44122         |\n",
            "| policy_loss             | -0.64588344   |\n",
            "| qf1_loss                | 1.9976483e-06 |\n",
            "| qf2_loss                | 8.107806e-07  |\n",
            "| time_elapsed            | 221           |\n",
            "| total timesteps         | 44221         |\n",
            "| value_loss              | 0.00012154999 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008206128   |\n",
            "| ent_coef_loss           | 1.13624       |\n",
            "| entropy                 | 0.9643948     |\n",
            "| episodes                | 11560         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 44192         |\n",
            "| policy_loss             | -0.66372824   |\n",
            "| qf1_loss                | 5.420476e-07  |\n",
            "| qf2_loss                | 2.392776e-07  |\n",
            "| time_elapsed            | 221           |\n",
            "| total timesteps         | 44291         |\n",
            "| value_loss              | 0.00014986639 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008246185   |\n",
            "| ent_coef_loss           | 0.7128681     |\n",
            "| entropy                 | 1.0220988     |\n",
            "| episodes                | 11570         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 44333         |\n",
            "| policy_loss             | -0.6142025    |\n",
            "| qf1_loss                | 8.055049e-07  |\n",
            "| qf2_loss                | 2.15581e-07   |\n",
            "| time_elapsed            | 222           |\n",
            "| total timesteps         | 44432         |\n",
            "| value_loss              | 0.00012620623 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008236538   |\n",
            "| ent_coef_loss           | 1.1509721     |\n",
            "| entropy                 | 1.0881181     |\n",
            "| episodes                | 11580         |\n",
            "| fps                     | 199           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 44423         |\n",
            "| policy_loss             | -0.6119031    |\n",
            "| qf1_loss                | 9.835201e-07  |\n",
            "| qf2_loss                | 1.9897298e-07 |\n",
            "| time_elapsed            | 222           |\n",
            "| total timesteps         | 44522         |\n",
            "| value_loss              | 0.0001268787  |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008206281    |\n",
            "| ent_coef_loss           | 0.9766125      |\n",
            "| entropy                 | 0.93811285     |\n",
            "| episodes                | 11590          |\n",
            "| fps                     | 200            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 44520          |\n",
            "| policy_loss             | -0.6151626     |\n",
            "| qf1_loss                | 6.0826994e-07  |\n",
            "| qf2_loss                | 3.0714023e-07  |\n",
            "| time_elapsed            | 223            |\n",
            "| total timesteps         | 44619          |\n",
            "| value_loss              | 0.000116471456 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008243731   |\n",
            "| ent_coef_loss           | 1.8782277     |\n",
            "| entropy                 | 0.9281386     |\n",
            "| episodes                | 11600         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 44617         |\n",
            "| policy_loss             | -0.6385287    |\n",
            "| qf1_loss                | 3.5846523e-07 |\n",
            "| qf2_loss                | 3.0931534e-07 |\n",
            "| time_elapsed            | 223           |\n",
            "| total timesteps         | 44716         |\n",
            "| value_loss              | 0.00010024656 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008230056    |\n",
            "| ent_coef_loss           | 0.37020355     |\n",
            "| entropy                 | 0.9176686      |\n",
            "| episodes                | 11610          |\n",
            "| fps                     | 200            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 44694          |\n",
            "| policy_loss             | -0.63293374    |\n",
            "| qf1_loss                | 1.0364549e-06  |\n",
            "| qf2_loss                | 4.997268e-07   |\n",
            "| time_elapsed            | 223            |\n",
            "| total timesteps         | 44793          |\n",
            "| value_loss              | 0.000108181135 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008322182   |\n",
            "| ent_coef_loss           | -1.4518286    |\n",
            "| entropy                 | 1.1116242     |\n",
            "| episodes                | 11620         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 44816         |\n",
            "| policy_loss             | -0.5991515    |\n",
            "| qf1_loss                | 2.8523318e-06 |\n",
            "| qf2_loss                | 1.8640444e-06 |\n",
            "| time_elapsed            | 224           |\n",
            "| total timesteps         | 44915         |\n",
            "| value_loss              | 0.00015411168 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008267705   |\n",
            "| ent_coef_loss           | -0.721592     |\n",
            "| entropy                 | 1.0536683     |\n",
            "| episodes                | 11630         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 44872         |\n",
            "| policy_loss             | -0.6082823    |\n",
            "| qf1_loss                | 9.875773e-07  |\n",
            "| qf2_loss                | 1.0735685e-06 |\n",
            "| time_elapsed            | 224           |\n",
            "| total timesteps         | 44971         |\n",
            "| value_loss              | 0.00013366228 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008204481   |\n",
            "| ent_coef_loss           | -2.2826383    |\n",
            "| entropy                 | 1.0488585     |\n",
            "| episodes                | 11640         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 44970         |\n",
            "| policy_loss             | -0.6304574    |\n",
            "| qf1_loss                | 3.423075e-07  |\n",
            "| qf2_loss                | 1.0479299e-07 |\n",
            "| time_elapsed            | 225           |\n",
            "| total timesteps         | 45069         |\n",
            "| value_loss              | 0.0001622875  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008135984   |\n",
            "| ent_coef_loss           | -0.5554899    |\n",
            "| entropy                 | 1.170996      |\n",
            "| episodes                | 11650         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 45033         |\n",
            "| policy_loss             | -0.58183      |\n",
            "| qf1_loss                | 3.1897207e-07 |\n",
            "| qf2_loss                | 2.7359897e-07 |\n",
            "| time_elapsed            | 225           |\n",
            "| total timesteps         | 45132         |\n",
            "| value_loss              | 0.00012819779 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008185907   |\n",
            "| ent_coef_loss           | 0.7035791     |\n",
            "| entropy                 | 1.0028998     |\n",
            "| episodes                | 11660         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 45149         |\n",
            "| policy_loss             | -0.66258854   |\n",
            "| qf1_loss                | 4.3334612e-07 |\n",
            "| qf2_loss                | 4.6814853e-07 |\n",
            "| time_elapsed            | 226           |\n",
            "| total timesteps         | 45248         |\n",
            "| value_loss              | 0.00013694378 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00815801    |\n",
            "| ent_coef_loss           | 1.7354221     |\n",
            "| entropy                 | 1.0332911     |\n",
            "| episodes                | 11670         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 45220         |\n",
            "| policy_loss             | -0.63911533   |\n",
            "| qf1_loss                | 4.688235e-07  |\n",
            "| qf2_loss                | 1.4452382e-07 |\n",
            "| time_elapsed            | 226           |\n",
            "| total timesteps         | 45319         |\n",
            "| value_loss              | 0.00012926754 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.00820242     |\n",
            "| ent_coef_loss           | -1.2949356     |\n",
            "| entropy                 | 1.1111219      |\n",
            "| episodes                | 11680          |\n",
            "| fps                     | 200            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 45312          |\n",
            "| policy_loss             | -0.59696674    |\n",
            "| qf1_loss                | 9.00906e-07    |\n",
            "| qf2_loss                | 2.869064e-07   |\n",
            "| time_elapsed            | 226            |\n",
            "| total timesteps         | 45411          |\n",
            "| value_loss              | 0.000101641315 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0082837     |\n",
            "| ent_coef_loss           | 0.045490116   |\n",
            "| entropy                 | 1.1469731     |\n",
            "| episodes                | 11690         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 45404         |\n",
            "| policy_loss             | -0.6074144    |\n",
            "| qf1_loss                | 1.6411094e-06 |\n",
            "| qf2_loss                | 4.1179473e-07 |\n",
            "| time_elapsed            | 227           |\n",
            "| total timesteps         | 45503         |\n",
            "| value_loss              | 0.00014860186 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00825682    |\n",
            "| ent_coef_loss           | 1.0040885     |\n",
            "| entropy                 | 0.9007016     |\n",
            "| episodes                | 11700         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 45504         |\n",
            "| policy_loss             | -0.6538425    |\n",
            "| qf1_loss                | 4.2724758e-07 |\n",
            "| qf2_loss                | 1.0430759e-07 |\n",
            "| time_elapsed            | 227           |\n",
            "| total timesteps         | 45603         |\n",
            "| value_loss              | 0.00010604932 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008277875    |\n",
            "| ent_coef_loss           | 0.6695684      |\n",
            "| entropy                 | 1.0453762      |\n",
            "| episodes                | 11710          |\n",
            "| fps                     | 200            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 45606          |\n",
            "| policy_loss             | -0.64012563    |\n",
            "| qf1_loss                | 3.2251796e-07  |\n",
            "| qf2_loss                | 2.0847492e-07  |\n",
            "| time_elapsed            | 228            |\n",
            "| total timesteps         | 45705          |\n",
            "| value_loss              | 0.000114606075 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008277997   |\n",
            "| ent_coef_loss           | -1.9455255    |\n",
            "| entropy                 | 1.1786875     |\n",
            "| episodes                | 11720         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 45678         |\n",
            "| policy_loss             | -0.5847653    |\n",
            "| qf1_loss                | 3.6407647e-07 |\n",
            "| qf2_loss                | 1.5344371e-07 |\n",
            "| time_elapsed            | 228           |\n",
            "| total timesteps         | 45777         |\n",
            "| value_loss              | 0.00014356885 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008223916   |\n",
            "| ent_coef_loss           | -0.39142993   |\n",
            "| entropy                 | 1.0844085     |\n",
            "| episodes                | 11730         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 45768         |\n",
            "| policy_loss             | -0.6119185    |\n",
            "| qf1_loss                | 2.7593342e-07 |\n",
            "| qf2_loss                | 4.8608683e-07 |\n",
            "| time_elapsed            | 229           |\n",
            "| total timesteps         | 45867         |\n",
            "| value_loss              | 0.00015161952 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008181006   |\n",
            "| ent_coef_loss           | -0.9146853    |\n",
            "| entropy                 | 1.0640335     |\n",
            "| episodes                | 11740         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 45875         |\n",
            "| policy_loss             | -0.6070955    |\n",
            "| qf1_loss                | 1.6859813e-07 |\n",
            "| qf2_loss                | 2.854714e-07  |\n",
            "| time_elapsed            | 229           |\n",
            "| total timesteps         | 45974         |\n",
            "| value_loss              | 0.00013048778 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008174537   |\n",
            "| ent_coef_loss           | -1.4813507    |\n",
            "| entropy                 | 1.0478008     |\n",
            "| episodes                | 11750         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 45967         |\n",
            "| policy_loss             | -0.61220336   |\n",
            "| qf1_loss                | 1.1394998e-06 |\n",
            "| qf2_loss                | 1.7302183e-07 |\n",
            "| time_elapsed            | 230           |\n",
            "| total timesteps         | 46066         |\n",
            "| value_loss              | 0.00013093333 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008244105   |\n",
            "| ent_coef_loss           | 0.85939276    |\n",
            "| entropy                 | 1.0300207     |\n",
            "| episodes                | 11760         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 46067         |\n",
            "| policy_loss             | -0.651114     |\n",
            "| qf1_loss                | 8.6735906e-07 |\n",
            "| qf2_loss                | 2.0298259e-07 |\n",
            "| time_elapsed            | 230           |\n",
            "| total timesteps         | 46166         |\n",
            "| value_loss              | 0.00012127136 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008260565   |\n",
            "| ent_coef_loss           | 0.67819846    |\n",
            "| entropy                 | 0.98542553    |\n",
            "| episodes                | 11770         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 46147         |\n",
            "| policy_loss             | -0.6080041    |\n",
            "| qf1_loss                | 4.956348e-07  |\n",
            "| qf2_loss                | 1.6511773e-07 |\n",
            "| time_elapsed            | 231           |\n",
            "| total timesteps         | 46246         |\n",
            "| value_loss              | 0.00014020668 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008307453   |\n",
            "| ent_coef_loss           | 1.1879733     |\n",
            "| entropy                 | 1.0526851     |\n",
            "| episodes                | 11780         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 46239         |\n",
            "| policy_loss             | -0.63653195   |\n",
            "| qf1_loss                | 1.5526776e-06 |\n",
            "| qf2_loss                | 5.2146436e-07 |\n",
            "| time_elapsed            | 231           |\n",
            "| total timesteps         | 46338         |\n",
            "| value_loss              | 0.00015329197 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008337967   |\n",
            "| ent_coef_loss           | -1.027466     |\n",
            "| entropy                 | 1.0225872     |\n",
            "| episodes                | 11790         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 46339         |\n",
            "| policy_loss             | -0.6081008    |\n",
            "| qf1_loss                | 5.700827e-07  |\n",
            "| qf2_loss                | 4.5519482e-07 |\n",
            "| time_elapsed            | 231           |\n",
            "| total timesteps         | 46438         |\n",
            "| value_loss              | 0.00014915841 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0083239125  |\n",
            "| ent_coef_loss           | -0.4237577    |\n",
            "| entropy                 | 1.012855      |\n",
            "| episodes                | 11800         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 46418         |\n",
            "| policy_loss             | -0.63549376   |\n",
            "| qf1_loss                | 1.4007974e-06 |\n",
            "| qf2_loss                | 7.7793936e-07 |\n",
            "| time_elapsed            | 232           |\n",
            "| total timesteps         | 46517         |\n",
            "| value_loss              | 0.00020207951 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008257423   |\n",
            "| ent_coef_loss           | 0.77127516    |\n",
            "| entropy                 | 1.025426      |\n",
            "| episodes                | 11810         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 46493         |\n",
            "| policy_loss             | -0.6467352    |\n",
            "| qf1_loss                | 2.0862095e-07 |\n",
            "| qf2_loss                | 1.54968e-07   |\n",
            "| time_elapsed            | 232           |\n",
            "| total timesteps         | 46592         |\n",
            "| value_loss              | 0.00010289463 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008207889   |\n",
            "| ent_coef_loss           | 0.28565726    |\n",
            "| entropy                 | 1.1212213     |\n",
            "| episodes                | 11820         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 46564         |\n",
            "| policy_loss             | -0.6239096    |\n",
            "| qf1_loss                | 9.676829e-07  |\n",
            "| qf2_loss                | 3.4885153e-07 |\n",
            "| time_elapsed            | 232           |\n",
            "| total timesteps         | 46663         |\n",
            "| value_loss              | 0.00016291636 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008198986   |\n",
            "| ent_coef_loss           | 0.7526237     |\n",
            "| entropy                 | 1.0929587     |\n",
            "| episodes                | 11830         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 46643         |\n",
            "| policy_loss             | -0.6236576    |\n",
            "| qf1_loss                | 7.9906596e-07 |\n",
            "| qf2_loss                | 3.0755874e-07 |\n",
            "| time_elapsed            | 233           |\n",
            "| total timesteps         | 46742         |\n",
            "| value_loss              | 0.00015002323 |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008316418    |\n",
            "| ent_coef_loss           | 1.1982347      |\n",
            "| entropy                 | 1.1158142      |\n",
            "| episodes                | 11840          |\n",
            "| fps                     | 200            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 46748          |\n",
            "| policy_loss             | -0.6222206     |\n",
            "| qf1_loss                | 6.87506e-07    |\n",
            "| qf2_loss                | 1.4938257e-07  |\n",
            "| time_elapsed            | 233            |\n",
            "| total timesteps         | 46847          |\n",
            "| value_loss              | 0.000116157484 |\n",
            "--------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008249272    |\n",
            "| ent_coef_loss           | -0.9945792     |\n",
            "| entropy                 | 1.0994076      |\n",
            "| episodes                | 11850          |\n",
            "| fps                     | 200            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 46834          |\n",
            "| policy_loss             | -0.6068294     |\n",
            "| qf1_loss                | 5.23594e-07    |\n",
            "| qf2_loss                | 1.17258026e-07 |\n",
            "| time_elapsed            | 234            |\n",
            "| total timesteps         | 46933          |\n",
            "| value_loss              | 0.00012788677  |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00822183    |\n",
            "| ent_coef_loss           | -1.7317157    |\n",
            "| entropy                 | 1.1791937     |\n",
            "| episodes                | 11860         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 46932         |\n",
            "| policy_loss             | -0.5700727    |\n",
            "| qf1_loss                | 4.527617e-07  |\n",
            "| qf2_loss                | 4.628834e-07  |\n",
            "| time_elapsed            | 234           |\n",
            "| total timesteps         | 47031         |\n",
            "| value_loss              | 0.00011225601 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008150689   |\n",
            "| ent_coef_loss           | 0.43106043    |\n",
            "| entropy                 | 1.0783517     |\n",
            "| episodes                | 11870         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 47041         |\n",
            "| policy_loss             | -0.6349683    |\n",
            "| qf1_loss                | 2.8606354e-07 |\n",
            "| qf2_loss                | 1.8788885e-06 |\n",
            "| time_elapsed            | 235           |\n",
            "| total timesteps         | 47140         |\n",
            "| value_loss              | 0.00012935532 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008197833   |\n",
            "| ent_coef_loss           | 0.3291399     |\n",
            "| entropy                 | 0.98360395    |\n",
            "| episodes                | 11880         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 47156         |\n",
            "| policy_loss             | -0.609695     |\n",
            "| qf1_loss                | 4.232475e-07  |\n",
            "| qf2_loss                | 2.0592379e-06 |\n",
            "| time_elapsed            | 235           |\n",
            "| total timesteps         | 47255         |\n",
            "| value_loss              | 0.00012664117 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008176712   |\n",
            "| ent_coef_loss           | 0.002099216   |\n",
            "| entropy                 | 1.027951      |\n",
            "| episodes                | 11890         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 47228         |\n",
            "| policy_loss             | -0.6199203    |\n",
            "| qf1_loss                | 2.5980438e-07 |\n",
            "| qf2_loss                | 2.6486482e-06 |\n",
            "| time_elapsed            | 236           |\n",
            "| total timesteps         | 47327         |\n",
            "| value_loss              | 0.00018401729 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008121863   |\n",
            "| ent_coef_loss           | 0.6184534     |\n",
            "| entropy                 | 1.0114238     |\n",
            "| episodes                | 11900         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 47333         |\n",
            "| policy_loss             | -0.5915954    |\n",
            "| qf1_loss                | 6.099714e-07  |\n",
            "| qf2_loss                | 4.4664978e-07 |\n",
            "| time_elapsed            | 236           |\n",
            "| total timesteps         | 47432         |\n",
            "| value_loss              | 0.00011739416 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008193381   |\n",
            "| ent_coef_loss           | 0.25032407    |\n",
            "| entropy                 | 1.0646018     |\n",
            "| episodes                | 11910         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 47443         |\n",
            "| policy_loss             | -0.6098268    |\n",
            "| qf1_loss                | 2.6101225e-07 |\n",
            "| qf2_loss                | 1.2643966e-07 |\n",
            "| time_elapsed            | 237           |\n",
            "| total timesteps         | 47542         |\n",
            "| value_loss              | 9.925226e-05  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008198614   |\n",
            "| ent_coef_loss           | -0.15829098   |\n",
            "| entropy                 | 1.0044754     |\n",
            "| episodes                | 11920         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 47514         |\n",
            "| policy_loss             | -0.5775441    |\n",
            "| qf1_loss                | 9.803266e-07  |\n",
            "| qf2_loss                | 4.263476e-07  |\n",
            "| time_elapsed            | 237           |\n",
            "| total timesteps         | 47613         |\n",
            "| value_loss              | 0.00011251705 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00823618    |\n",
            "| ent_coef_loss           | 0.5486386     |\n",
            "| entropy                 | 1.0372648     |\n",
            "| episodes                | 11930         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 47590         |\n",
            "| policy_loss             | -0.62764764   |\n",
            "| qf1_loss                | 8.925588e-07  |\n",
            "| qf2_loss                | 2.4144558e-07 |\n",
            "| time_elapsed            | 237           |\n",
            "| total timesteps         | 47689         |\n",
            "| value_loss              | 0.00013571588 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0082196705  |\n",
            "| ent_coef_loss           | -1.3344462    |\n",
            "| entropy                 | 1.1002961     |\n",
            "| episodes                | 11940         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 47667         |\n",
            "| policy_loss             | -0.57422954   |\n",
            "| qf1_loss                | 1.8221963e-06 |\n",
            "| qf2_loss                | 2.1111079e-07 |\n",
            "| time_elapsed            | 238           |\n",
            "| total timesteps         | 47766         |\n",
            "| value_loss              | 0.0001639943  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008250145   |\n",
            "| ent_coef_loss           | 0.027342409   |\n",
            "| entropy                 | 1.0200408     |\n",
            "| episodes                | 11950         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 47786         |\n",
            "| policy_loss             | -0.67042077   |\n",
            "| qf1_loss                | 2.2724269e-06 |\n",
            "| qf2_loss                | 2.61134e-07   |\n",
            "| time_elapsed            | 238           |\n",
            "| total timesteps         | 47885         |\n",
            "| value_loss              | 0.0001652875  |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008211463   |\n",
            "| ent_coef_loss           | -1.6920645    |\n",
            "| entropy                 | 1.0785803     |\n",
            "| episodes                | 11960         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 47846         |\n",
            "| policy_loss             | -0.5966273    |\n",
            "| qf1_loss                | 1.7612203e-06 |\n",
            "| qf2_loss                | 4.8201315e-07 |\n",
            "| time_elapsed            | 239           |\n",
            "| total timesteps         | 47945         |\n",
            "| value_loss              | 0.00016655965 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008181743   |\n",
            "| ent_coef_loss           | -0.44065318   |\n",
            "| entropy                 | 1.028636      |\n",
            "| episodes                | 11970         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 47935         |\n",
            "| policy_loss             | -0.6450335    |\n",
            "| qf1_loss                | 5.642886e-07  |\n",
            "| qf2_loss                | 4.1084678e-07 |\n",
            "| time_elapsed            | 239           |\n",
            "| total timesteps         | 48034         |\n",
            "| value_loss              | 0.00018555403 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008178526   |\n",
            "| ent_coef_loss           | 1.5669515     |\n",
            "| entropy                 | 1.0574038     |\n",
            "| episodes                | 11980         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 48038         |\n",
            "| policy_loss             | -0.6219924    |\n",
            "| qf1_loss                | 3.8875123e-07 |\n",
            "| qf2_loss                | 2.2841812e-07 |\n",
            "| time_elapsed            | 240           |\n",
            "| total timesteps         | 48137         |\n",
            "| value_loss              | 0.00013695261 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008189003   |\n",
            "| ent_coef_loss           | 0.77762055    |\n",
            "| entropy                 | 0.9542203     |\n",
            "| episodes                | 11990         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 48128         |\n",
            "| policy_loss             | -0.64426124   |\n",
            "| qf1_loss                | 5.586295e-07  |\n",
            "| qf2_loss                | 9.250691e-08  |\n",
            "| time_elapsed            | 240           |\n",
            "| total timesteps         | 48227         |\n",
            "| value_loss              | 0.00013494154 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008244361   |\n",
            "| ent_coef_loss           | 1.3946614     |\n",
            "| entropy                 | 0.953153      |\n",
            "| episodes                | 12000         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 48239         |\n",
            "| policy_loss             | -0.6557348    |\n",
            "| qf1_loss                | 9.877034e-07  |\n",
            "| qf2_loss                | 2.1385729e-07 |\n",
            "| time_elapsed            | 241           |\n",
            "| total timesteps         | 48338         |\n",
            "| value_loss              | 0.00011720098 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008262527   |\n",
            "| ent_coef_loss           | 1.083783      |\n",
            "| entropy                 | 1.0566957     |\n",
            "| episodes                | 12010         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 48327         |\n",
            "| policy_loss             | -0.6473015    |\n",
            "| qf1_loss                | 3.796893e-07  |\n",
            "| qf2_loss                | 2.7655324e-07 |\n",
            "| time_elapsed            | 241           |\n",
            "| total timesteps         | 48426         |\n",
            "| value_loss              | 0.00014776929 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00827458    |\n",
            "| ent_coef_loss           | 0.42774555    |\n",
            "| entropy                 | 1.0658578     |\n",
            "| episodes                | 12020         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 48416         |\n",
            "| policy_loss             | -0.5997771    |\n",
            "| qf1_loss                | 5.6403235e-07 |\n",
            "| qf2_loss                | 2.056989e-07  |\n",
            "| time_elapsed            | 241           |\n",
            "| total timesteps         | 48515         |\n",
            "| value_loss              | 0.00010505915 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00830358    |\n",
            "| ent_coef_loss           | 1.2742088     |\n",
            "| entropy                 | 0.9520669     |\n",
            "| episodes                | 12030         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 48502         |\n",
            "| policy_loss             | -0.6384642    |\n",
            "| qf1_loss                | 1.9288848e-07 |\n",
            "| qf2_loss                | 3.3816167e-07 |\n",
            "| time_elapsed            | 242           |\n",
            "| total timesteps         | 48601         |\n",
            "| value_loss              | 0.00011019857 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.00830052    |\n",
            "| ent_coef_loss           | -0.15231754   |\n",
            "| entropy                 | 0.98647106    |\n",
            "| episodes                | 12040         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 48603         |\n",
            "| policy_loss             | -0.61678916   |\n",
            "| qf1_loss                | 3.887038e-07  |\n",
            "| qf2_loss                | 2.6961075e-07 |\n",
            "| time_elapsed            | 242           |\n",
            "| total timesteps         | 48702         |\n",
            "| value_loss              | 0.00013931602 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008267371   |\n",
            "| ent_coef_loss           | 0.44525826    |\n",
            "| entropy                 | 1.0217102     |\n",
            "| episodes                | 12050         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 48668         |\n",
            "| policy_loss             | -0.651263     |\n",
            "| qf1_loss                | 3.3026492e-07 |\n",
            "| qf2_loss                | 5.1505594e-07 |\n",
            "| time_elapsed            | 243           |\n",
            "| total timesteps         | 48767         |\n",
            "| value_loss              | 0.00012296153 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0082602855  |\n",
            "| ent_coef_loss           | 1.7457796     |\n",
            "| entropy                 | 0.8740206     |\n",
            "| episodes                | 12060         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 48777         |\n",
            "| policy_loss             | -0.67235494   |\n",
            "| qf1_loss                | 7.147813e-07  |\n",
            "| qf2_loss                | 5.849213e-07  |\n",
            "| time_elapsed            | 243           |\n",
            "| total timesteps         | 48876         |\n",
            "| value_loss              | 0.00011973521 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008277453   |\n",
            "| ent_coef_loss           | 1.6620471     |\n",
            "| entropy                 | 0.9845667     |\n",
            "| episodes                | 12070         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 48887         |\n",
            "| policy_loss             | -0.64374876   |\n",
            "| qf1_loss                | 2.7979198e-07 |\n",
            "| qf2_loss                | 3.3024236e-07 |\n",
            "| time_elapsed            | 244           |\n",
            "| total timesteps         | 48986         |\n",
            "| value_loss              | 0.0001240359  |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| current_lr              | 0.0003         |\n",
            "| ent_coef                | 0.008323198    |\n",
            "| ent_coef_loss           | -0.034274206   |\n",
            "| entropy                 | 1.0683229      |\n",
            "| episodes                | 12080          |\n",
            "| fps                     | 200            |\n",
            "| mean 100 episode reward | 0.9            |\n",
            "| n_updates               | 48987          |\n",
            "| policy_loss             | -0.59773284    |\n",
            "| qf1_loss                | 2.5168902e-07  |\n",
            "| qf2_loss                | 1.019615e-06   |\n",
            "| time_elapsed            | 244            |\n",
            "| total timesteps         | 49086          |\n",
            "| value_loss              | 0.000106139894 |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008386826   |\n",
            "| ent_coef_loss           | -0.38474876   |\n",
            "| entropy                 | 1.0118823     |\n",
            "| episodes                | 12090         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 49083         |\n",
            "| policy_loss             | -0.61581165   |\n",
            "| qf1_loss                | 8.293437e-07  |\n",
            "| qf2_loss                | 2.4311694e-07 |\n",
            "| time_elapsed            | 245           |\n",
            "| total timesteps         | 49182         |\n",
            "| value_loss              | 0.00013639644 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008359528   |\n",
            "| ent_coef_loss           | -0.99861854   |\n",
            "| entropy                 | 1.0717226     |\n",
            "| episodes                | 12100         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 49184         |\n",
            "| policy_loss             | -0.61925435   |\n",
            "| qf1_loss                | 1.1261061e-06 |\n",
            "| qf2_loss                | 8.8342773e-07 |\n",
            "| time_elapsed            | 245           |\n",
            "| total timesteps         | 49283         |\n",
            "| value_loss              | 0.00017268385 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008396378   |\n",
            "| ent_coef_loss           | 0.91689277    |\n",
            "| entropy                 | 0.96226376    |\n",
            "| episodes                | 12110         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 49285         |\n",
            "| policy_loss             | -0.6497816    |\n",
            "| qf1_loss                | 3.829349e-07  |\n",
            "| qf2_loss                | 3.8794255e-07 |\n",
            "| time_elapsed            | 246           |\n",
            "| total timesteps         | 49384         |\n",
            "| value_loss              | 0.00013436438 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0083932355  |\n",
            "| ent_coef_loss           | -0.22193784   |\n",
            "| entropy                 | 1.0282738     |\n",
            "| episodes                | 12120         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 49365         |\n",
            "| policy_loss             | -0.63168      |\n",
            "| qf1_loss                | 6.973081e-07  |\n",
            "| qf2_loss                | 1.9253686e-07 |\n",
            "| time_elapsed            | 246           |\n",
            "| total timesteps         | 49464         |\n",
            "| value_loss              | 0.00014285865 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008363803   |\n",
            "| ent_coef_loss           | 0.17524707    |\n",
            "| entropy                 | 1.0058274     |\n",
            "| episodes                | 12130         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 49438         |\n",
            "| policy_loss             | -0.6488826    |\n",
            "| qf1_loss                | 1.3211343e-06 |\n",
            "| qf2_loss                | 2.7522734e-07 |\n",
            "| time_elapsed            | 246           |\n",
            "| total timesteps         | 49537         |\n",
            "| value_loss              | 0.00015935123 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.0083763385  |\n",
            "| ent_coef_loss           | -1.2783363    |\n",
            "| entropy                 | 1.0059252     |\n",
            "| episodes                | 12140         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 49515         |\n",
            "| policy_loss             | -0.57872885   |\n",
            "| qf1_loss                | 2.6795686e-07 |\n",
            "| qf2_loss                | 3.037891e-07  |\n",
            "| time_elapsed            | 247           |\n",
            "| total timesteps         | 49614         |\n",
            "| value_loss              | 0.00012387447 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008376163   |\n",
            "| ent_coef_loss           | 0.25720823    |\n",
            "| entropy                 | 0.98143184    |\n",
            "| episodes                | 12150         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 49602         |\n",
            "| policy_loss             | -0.63174057   |\n",
            "| qf1_loss                | 1.1482507e-06 |\n",
            "| qf2_loss                | 1.0647368e-06 |\n",
            "| time_elapsed            | 247           |\n",
            "| total timesteps         | 49701         |\n",
            "| value_loss              | 0.00014369481 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008405663   |\n",
            "| ent_coef_loss           | 0.12185177    |\n",
            "| entropy                 | 0.9773882     |\n",
            "| episodes                | 12160         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 49738         |\n",
            "| policy_loss             | -0.6507607    |\n",
            "| qf1_loss                | 2.3075278e-07 |\n",
            "| qf2_loss                | 3.138329e-07  |\n",
            "| time_elapsed            | 248           |\n",
            "| total timesteps         | 49837         |\n",
            "| value_loss              | 0.00013367773 |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| current_lr              | 0.0003        |\n",
            "| ent_coef                | 0.008415064   |\n",
            "| ent_coef_loss           | 0.8603002     |\n",
            "| entropy                 | 1.0740676     |\n",
            "| episodes                | 12170         |\n",
            "| fps                     | 200           |\n",
            "| mean 100 episode reward | 0.9           |\n",
            "| n_updates               | 49796         |\n",
            "| policy_loss             | -0.62374914   |\n",
            "| qf1_loss                | 6.043863e-07  |\n",
            "| qf2_loss                | 1.565993e-06  |\n",
            "| time_elapsed            | 248           |\n",
            "| total timesteps         | 49895         |\n",
            "| value_loss              | 0.00012061295 |\n",
            "-------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoXAg2AleTV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from stable_baselines.common.evaluation import evaluate_policy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thbXsHdmuD6l",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "We can evaluate the trained agent and see how it compares our untrained agent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgM7cigseDmt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5724c421-e25a-44cf-d9e0-088071bfc7c0"
      },
      "source": [
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=50000)\n",
        "\n",
        "print(\"mean_reward: \" + str(mean_reward) + \"+/- \" + str(std_reward))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean_reward: 1.4349191705089428+/- 2.220446049250313e-16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9UiOawKlB04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f293f70-d973-4ef8-a1f6-92d93c1d5917"
      },
      "source": [
        "#!python -m train.py --algo sac2 --env fishing-v1 -n 50000 -optimize --n-trials 1000 --n-jobs 2 --sampler tpe --pruner median#"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/bin/python3: Error while finding module specification for 'train.py' (ModuleNotFoundError: No module named 'train')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBKtdt26-Nbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del model\n",
        "\n",
        "model = SAC.load(\"fishing-v1\")\n",
        "\n",
        "obs = env.reset()\n",
        "\n",
        "\n",
        "#render = lambda : plt.imshow(env.render(mode='rgb_array'))\n",
        " \n",
        "#env.reset()\n",
        "#while True: \n",
        "  #action, _states = model.predict(obs)\n",
        "  #obs, rewards, dones, info = env.step(action)\n",
        "  #env.render()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}